{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFI1I2WoeEuL",
        "outputId": "081a4f79-91c6-4ae4-a9c7-63cef44d328f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "train_data = pd.read_csv('./data/eastmoney_bpr_train.csv', delimiter='<')\n",
        "valid_data = pd.read_csv('./data/eastmoney_bpr_valid.csv', delimiter='<')\n",
        "test_data = pd.read_csv('./data/eastmoney_bpr_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['item_title', 'item_author_cate', 'article_author',\n",
              "       'article_source_cate', 'month', 'eastmoney_robo_journalism',\n",
              "       'media_robo_journalism', 'SMA_robo_journalism', 'viral',\n",
              "       'sentiment_score', 'topics_val1', 'topics_val2', 'topics_val3',\n",
              "       'topics_val4', 'topics_val5', 'stock_code', 'IndustryCode1',\n",
              "       'IndustryName1', 'IndustryCode2', 'IndustryName2',\n",
              "       'item_author_reduced', 'article_author_reduced',\n",
              "       'article_source_reduced', 'stock_code_index', 'item_author_cate_index',\n",
              "       'article_author_index', 'article_source_cate_index', 'month_index',\n",
              "       'IndustryCode1_index', 'IndustryCode2_index',\n",
              "       'eastmoney_robo_journalism_index', 'media_robo_journalism_index',\n",
              "       'SMA_robo_journalism_index', 'item_author_reduced_index',\n",
              "       'article_author_reduced_index', 'article_source_reduced_index',\n",
              "       'neg_item_title', 'neg_item_author_cate', 'neg_article_author',\n",
              "       'neg_article_source_cate', 'neg_month', 'neg_eastmoney_robo_journalism',\n",
              "       'neg_media_robo_journalism', 'neg_SMA_robo_journalism', 'neg_viral',\n",
              "       'neg_sentiment_score', 'neg_topics_val1', 'neg_topics_val2',\n",
              "       'neg_topics_val3', 'neg_topics_val4', 'neg_topics_val5',\n",
              "       'neg_stock_code', 'neg_IndustryCode1', 'neg_IndustryName1',\n",
              "       'neg_IndustryCode2', 'neg_IndustryName2', 'neg_item_author_reduced',\n",
              "       'neg_article_author_reduced', 'neg_article_source_reduced',\n",
              "       'neg_stock_code_index', 'neg_item_author_cate_index',\n",
              "       'neg_article_author_index', 'neg_article_source_cate_index',\n",
              "       'neg_month_index', 'neg_IndustryCode1_index', 'neg_IndustryCode2_index',\n",
              "       'neg_eastmoney_robo_journalism_index',\n",
              "       'neg_media_robo_journalism_index', 'neg_SMA_robo_journalism_index',\n",
              "       'neg_item_author_reduced_index', 'neg_article_author_reduced_index',\n",
              "       'neg_article_source_reduced_index'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG4It742M82E"
      },
      "source": [
        "# Use machine learning models to predict virality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPW1-BTAuf_B"
      },
      "source": [
        "## XGboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oK8d03bH3jya",
        "outputId": "a231280e-ef5f-4604-a35e-008cd7a2a98c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=0.927 total time=   7.0s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=0.927 total time=   5.6s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=0.927 total time=   7.9s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=0.927 total time=   5.1s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=0.927 total time=   6.9s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=0.927 total time=   5.1s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0;, score=0.927 total time=   5.0s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0;, score=0.926 total time=   6.0s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0;, score=0.927 total time=   4.9s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=0.929 total time=  11.2s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=0.929 total time=  10.8s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=0.929 total time=   8.7s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=0.929 total time=  10.3s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=0.929 total time=  11.2s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=0.929 total time=   8.6s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=0.929 total time=   8.5s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=0.929 total time=  10.7s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=0.929 total time=   7.9s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=0.934 total time=  12.7s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=0.934 total time=  13.3s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=0.935 total time=  14.0s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9;, score=0.934 total time=  13.8s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9;, score=0.934 total time=  14.1s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9;, score=0.935 total time=  13.7s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=0.934 total time=  13.5s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=0.934 total time=  13.7s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=0.935 total time=  13.4s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.946 total time=   8.8s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.946 total time=   6.2s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.947 total time=   8.6s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=0.946 total time=   6.1s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=0.946 total time=   8.7s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=0.947 total time=   6.3s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.946 total time=   8.5s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.946 total time=   5.9s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.947 total time=   8.4s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.947 total time=  12.6s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.947 total time=  10.8s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.948 total time=  11.0s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9;, score=0.947 total time=  12.9s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9;, score=0.947 total time=  13.0s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9;, score=0.947 total time=  12.9s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.947 total time=  12.8s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.947 total time=  11.9s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.947 total time=  10.0s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.951 total time=  18.0s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.951 total time=  17.6s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.951 total time=  17.8s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9;, score=0.951 total time=  17.7s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9;, score=0.951 total time=  17.6s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9;, score=0.951 total time=  17.5s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.951 total time=  16.8s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.951 total time=  16.7s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.951 total time=  17.0s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=0.951 total time=   7.5s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=0.951 total time=   8.6s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=0.951 total time=   6.8s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9;, score=0.951 total time=   9.4s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9;, score=0.951 total time=   6.8s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9;, score=0.951 total time=   9.3s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=0.951 total time=   6.7s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=0.951 total time=   7.7s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=0.951 total time=   6.7s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8;, score=0.952 total time=  12.7s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8;, score=0.951 total time=  13.2s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8;, score=0.952 total time=  13.6s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9;, score=0.952 total time=  13.9s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9;, score=0.951 total time=  14.2s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9;, score=0.952 total time=  13.9s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=0.952 total time=  14.2s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=0.951 total time=  13.8s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=0.952 total time=  14.1s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8;, score=0.955 total time=  22.3s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8;, score=0.955 total time=  19.9s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8;, score=0.955 total time=  21.8s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=0.955 total time=  19.8s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=0.955 total time=  20.2s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=0.955 total time=  19.9s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=0.955 total time=  18.9s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=0.955 total time=  20.8s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=0.955 total time=  19.1s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8;, score=0.953 total time=   5.4s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8;, score=0.953 total time=   5.9s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8;, score=0.953 total time=   5.3s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9;, score=0.953 total time=   7.7s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9;, score=0.953 total time=   5.4s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9;, score=0.953 total time=   7.9s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.953 total time=   5.2s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.953 total time=   5.2s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.953 total time=   5.4s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8;, score=0.959 total time=  10.6s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8;, score=0.959 total time=   8.8s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8;, score=0.959 total time=  11.0s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9;, score=0.959 total time=  11.1s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9;, score=0.959 total time=   8.7s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9;, score=0.959 total time=   8.8s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0;, score=0.959 total time=  10.7s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0;, score=0.959 total time=  10.0s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0;, score=0.960 total time=   8.3s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8;, score=0.962 total time=  14.2s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8;, score=0.962 total time=  14.3s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8;, score=0.962 total time=  14.2s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9;, score=0.962 total time=  14.4s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9;, score=0.962 total time=  14.3s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9;, score=0.962 total time=  14.3s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0;, score=0.962 total time=  13.6s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0;, score=0.962 total time=  13.8s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0;, score=0.962 total time=  13.7s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.962 total time=   8.4s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.962 total time=   6.6s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.962 total time=   9.1s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9;, score=0.962 total time=   6.5s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9;, score=0.962 total time=   9.1s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9;, score=0.962 total time=   6.6s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.962 total time=   8.3s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.962 total time=   6.3s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.962 total time=   7.8s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.966 total time=  13.3s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.966 total time=  13.7s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.966 total time=  12.8s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9;, score=0.966 total time=  10.6s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9;, score=0.966 total time=  11.3s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9;, score=0.966 total time=  13.1s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.966 total time=  13.0s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.966 total time=  13.0s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.966 total time=  13.0s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=0.968 total time=  17.6s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=0.968 total time=  17.8s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=0.967 total time=  18.2s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=0.968 total time=  17.5s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=0.968 total time=  17.5s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=0.967 total time=  17.4s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.968 total time=  15.8s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.968 total time=  16.8s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.967 total time=  17.1s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=0.965 total time=   7.3s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=0.965 total time=   7.5s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=0.965 total time=   9.7s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9;, score=0.965 total time=   7.2s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9;, score=0.965 total time=   9.7s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9;, score=0.965 total time=   7.4s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=0.965 total time=   7.3s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=0.965 total time=   9.5s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=0.965 total time=   7.0s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=0.968 total time=  15.2s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=0.968 total time=  15.3s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=0.968 total time=  14.7s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.9;, score=0.968 total time=  13.8s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.9;, score=0.968 total time=  13.6s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.9;, score=0.968 total time=  13.7s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0;, score=0.968 total time=  14.1s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0;, score=0.968 total time=  13.6s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0;, score=0.968 total time=  13.4s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8;, score=0.969 total time=  22.7s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8;, score=0.969 total time=  20.3s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8;, score=0.969 total time=  22.6s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.9;, score=0.969 total time=  20.6s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.9;, score=0.969 total time=  22.6s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.9;, score=0.969 total time=  20.5s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=0.969 total time=  21.0s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=0.969 total time=  19.9s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=0.969 total time=  22.1s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8;, score=0.959 total time=   5.5s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8;, score=0.959 total time=   7.9s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8;, score=0.959 total time=   5.5s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9;, score=0.958 total time=   7.3s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9;, score=0.959 total time=   5.3s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9;, score=0.960 total time=   5.4s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0;, score=0.959 total time=   5.6s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0;, score=0.960 total time=   5.3s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0;, score=0.959 total time=   7.2s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8;, score=0.963 total time=   8.6s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8;, score=0.963 total time=   9.3s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8;, score=0.963 total time=  11.4s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9;, score=0.963 total time=  10.6s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9;, score=0.964 total time=   8.5s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9;, score=0.963 total time=  10.9s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0;, score=0.963 total time=  10.8s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0;, score=0.963 total time=   8.2s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0;, score=0.963 total time=   9.4s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8;, score=0.965 total time=  14.5s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8;, score=0.965 total time=  14.5s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8;, score=0.964 total time=  14.5s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9;, score=0.965 total time=  14.2s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9;, score=0.965 total time=  14.3s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9;, score=0.965 total time=  14.2s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0;, score=0.965 total time=  13.6s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0;, score=0.965 total time=  13.8s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0;, score=0.964 total time=  13.4s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8;, score=0.965 total time=   6.4s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8;, score=0.966 total time=   8.7s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8;, score=0.965 total time=   6.3s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9;, score=0.966 total time=   7.8s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9;, score=0.966 total time=   6.4s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9;, score=0.965 total time=   7.5s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.966 total time=   6.1s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.966 total time=   7.5s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.965 total time=   6.1s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8;, score=0.968 total time=  12.5s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8;, score=0.968 total time=  13.2s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8;, score=0.968 total time=  13.4s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9;, score=0.968 total time=  13.2s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9;, score=0.968 total time=  13.4s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9;, score=0.968 total time=  13.4s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.968 total time=  12.0s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.968 total time=  10.2s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.968 total time=  11.0s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8;, score=0.969 total time=  17.3s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8;, score=0.969 total time=  17.6s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8;, score=0.969 total time=  17.5s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9;, score=0.969 total time=  17.3s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9;, score=0.969 total time=  17.3s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9;, score=0.969 total time=  17.5s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.969 total time=  16.6s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.969 total time=  16.7s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.969 total time=  17.2s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8;, score=0.968 total time=   9.8s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8;, score=0.968 total time=   7.1s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8;, score=0.968 total time=   8.4s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.9;, score=0.968 total time=   9.2s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.9;, score=0.968 total time=   7.1s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.9;, score=0.968 total time=   9.7s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0;, score=0.968 total time=   6.9s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0;, score=0.968 total time=   8.8s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0;, score=0.968 total time=   7.1s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8;, score=0.970 total time=  12.7s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8;, score=0.970 total time=  13.1s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8;, score=0.969 total time=  13.0s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.9;, score=0.970 total time=  13.1s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.9;, score=0.970 total time=  13.0s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.9;, score=0.969 total time=  13.5s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0;, score=0.970 total time=  12.9s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0;, score=0.970 total time=  13.1s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0;, score=0.969 total time=  13.5s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8;, score=0.970 total time=  22.0s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8;, score=0.970 total time=  20.2s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8;, score=0.970 total time=  23.0s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.9;, score=0.970 total time=  19.9s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.9;, score=0.970 total time=  22.1s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.9;, score=0.970 total time=  20.2s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0;, score=0.970 total time=  22.0s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0;, score=0.970 total time=  19.5s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0;, score=0.970 total time=  21.3s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=0.932 total time=   5.2s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=0.932 total time=   5.2s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=0.933 total time=   5.8s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=0.932 total time=   5.1s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=0.932 total time=   7.5s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=0.933 total time=   5.0s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0;, score=0.932 total time=   6.4s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0;, score=0.932 total time=   4.9s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0;, score=0.933 total time=   5.0s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=0.937 total time=  10.3s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=0.936 total time=  11.2s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=0.937 total time=   8.6s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=0.937 total time=   8.7s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=0.936 total time=  11.0s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=0.937 total time=  10.0s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=0.937 total time=   8.1s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=0.936 total time=  10.5s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=0.937 total time=  10.5s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=0.942 total time=  14.6s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=0.942 total time=  14.5s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=0.942 total time=  14.6s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9;, score=0.942 total time=  14.2s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9;, score=0.942 total time=  14.3s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9;, score=0.942 total time=  14.3s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=0.942 total time=  13.4s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=0.942 total time=  11.7s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=0.942 total time=  11.5s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.954 total time=   7.4s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.954 total time=   6.4s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.954 total time=   7.3s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=0.954 total time=   6.4s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=0.954 total time=   7.2s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=0.954 total time=   6.5s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.954 total time=   6.5s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.954 total time=   6.3s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.954 total time=   6.6s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.957 total time=  13.7s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.956 total time=  13.8s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.956 total time=  13.7s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9;, score=0.957 total time=  13.6s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9;, score=0.956 total time=  13.5s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9;, score=0.956 total time=  12.7s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.957 total time=  10.7s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.956 total time=  11.2s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.956 total time=  13.2s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.959 total time=  18.8s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.959 total time=  18.5s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.959 total time=  18.7s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9;, score=0.959 total time=  18.5s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9;, score=0.959 total time=  18.8s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9;, score=0.959 total time=  18.5s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.959 total time=  18.0s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.959 total time=  19.0s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.959 total time=  18.0s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=0.960 total time=   9.5s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=0.960 total time=   7.6s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=0.960 total time=  10.0s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9;, score=0.960 total time=   7.6s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9;, score=0.960 total time=   7.7s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9;, score=0.960 total time=  10.0s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=0.960 total time=   7.4s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=0.960 total time=   9.6s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=0.960 total time=   9.2s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8;, score=0.962 total time=  15.9s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8;, score=0.962 total time=  15.8s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8;, score=0.962 total time=  16.1s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9;, score=0.962 total time=  15.8s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9;, score=0.962 total time=  16.4s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9;, score=0.962 total time=  16.0s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=0.962 total time=  14.1s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=0.962 total time=  14.0s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=0.962 total time=  13.4s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8;, score=0.964 total time=  22.1s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8;, score=0.964 total time=  24.7s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8;, score=0.964 total time=  22.1s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=0.964 total time=  23.2s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=0.964 total time=  23.9s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=0.964 total time=  22.5s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=0.964 total time=  24.1s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=0.964 total time=  22.0s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=0.964 total time=  21.6s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8;, score=0.955 total time=   6.9s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8;, score=0.956 total time=   5.4s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8;, score=0.956 total time=   5.6s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9;, score=0.956 total time=   5.7s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9;, score=0.956 total time=   5.3s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9;, score=0.956 total time=   7.6s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.955 total time=   5.0s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.956 total time=   7.5s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.956 total time=   5.1s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8;, score=0.960 total time=  11.0s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8;, score=0.961 total time=   8.6s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8;, score=0.961 total time=   9.1s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9;, score=0.961 total time=  10.9s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9;, score=0.962 total time=   9.2s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9;, score=0.961 total time=   8.4s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0;, score=0.960 total time=  10.4s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0;, score=0.962 total time=   9.4s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0;, score=0.961 total time=   8.0s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8;, score=0.964 total time=  14.3s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8;, score=0.964 total time=  14.2s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8;, score=0.964 total time=  14.4s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9;, score=0.964 total time=  13.9s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9;, score=0.964 total time=  14.0s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9;, score=0.964 total time=  14.0s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0;, score=0.964 total time=  13.5s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0;, score=0.964 total time=  13.2s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0;, score=0.964 total time=  13.5s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.966 total time=   6.6s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.966 total time=   7.0s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.966 total time=   7.0s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9;, score=0.966 total time=   6.6s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9;, score=0.966 total time=   8.4s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9;, score=0.966 total time=   6.5s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.966 total time=   8.9s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.966 total time=   6.3s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.966 total time=   8.9s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.968 total time=  13.4s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.969 total time=  12.6s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.968 total time=  10.9s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9;, score=0.969 total time=  11.4s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9;, score=0.968 total time=  13.1s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9;, score=0.968 total time=  13.4s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.969 total time=  12.9s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.968 total time=  12.9s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.968 total time=  12.9s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=0.969 total time=  17.6s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=0.969 total time=  18.1s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=0.969 total time=  18.4s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=0.969 total time=  17.7s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=0.969 total time=  17.5s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=0.969 total time=  17.4s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.969 total time=  16.5s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.969 total time=  17.0s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.969 total time=  17.2s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=0.969 total time=   9.8s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=0.969 total time=   7.9s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=0.969 total time=  10.3s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9;, score=0.969 total time=   9.5s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9;, score=0.969 total time=   7.9s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9;, score=0.969 total time=  10.2s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=0.969 total time=   7.9s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=0.969 total time=   7.7s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=0.969 total time=  10.2s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=0.970 total time=  16.0s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=0.971 total time=  16.2s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=0.970 total time=  15.7s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.9;, score=0.971 total time=  15.8s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.9;, score=0.971 total time=  15.9s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.9;, score=0.970 total time=  15.1s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0;, score=0.971 total time=  13.7s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0;, score=0.971 total time=  13.4s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0;, score=0.970 total time=  14.3s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8;, score=0.971 total time=  21.3s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8;, score=0.971 total time=  23.6s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8;, score=0.971 total time=  21.3s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.9;, score=0.971 total time=  23.6s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.9;, score=0.971 total time=  20.9s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.9;, score=0.971 total time=  22.8s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=0.971 total time=  20.7s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=0.971 total time=  21.2s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=0.971 total time=  20.4s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8;, score=0.962 total time=   6.2s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8;, score=0.962 total time=   5.3s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8;, score=0.961 total time=   7.6s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9;, score=0.961 total time=   5.1s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9;, score=0.962 total time=   8.8s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9;, score=0.961 total time=  16.6s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0;, score=0.962 total time=   5.0s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0;, score=0.962 total time=   6.4s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0;, score=0.962 total time=   5.0s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8;, score=0.965 total time=  11.0s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8;, score=0.965 total time=  10.4s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8;, score=0.965 total time=   8.3s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9;, score=0.965 total time=  10.7s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9;, score=0.965 total time=  10.7s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9;, score=0.965 total time=   8.3s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0;, score=0.965 total time=   9.6s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0;, score=0.965 total time=  10.3s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0;, score=0.965 total time=   8.3s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8;, score=0.967 total time=  13.4s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8;, score=0.966 total time=  13.8s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8;, score=0.966 total time=  14.1s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9;, score=0.967 total time=  14.0s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9;, score=0.967 total time=  14.0s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9;, score=0.966 total time=  15.1s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0;, score=0.967 total time=  13.3s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0;, score=0.967 total time=  13.5s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0;, score=0.966 total time=  13.3s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8;, score=0.968 total time=   9.0s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8;, score=0.968 total time=   6.5s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8;, score=0.968 total time=   9.0s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9;, score=0.968 total time=   6.5s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9;, score=0.968 total time=   8.6s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9;, score=0.968 total time=   6.4s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.968 total time=   7.5s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.968 total time=   6.3s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.968 total time=   7.2s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8;, score=0.970 total time=  13.4s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8;, score=0.970 total time=  13.3s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8;, score=0.970 total time=  13.4s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9;, score=0.970 total time=  10.6s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9;, score=0.970 total time=  10.7s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9;, score=0.970 total time=  12.7s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.970 total time=  12.8s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.970 total time=  12.8s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.970 total time=  13.0s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8;, score=0.970 total time=  17.5s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8;, score=0.970 total time=  17.6s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8;, score=0.970 total time=  17.8s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9;, score=0.970 total time=  17.7s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9;, score=0.970 total time=  17.2s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9;, score=0.970 total time=  17.4s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.970 total time=  16.9s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.970 total time=  17.2s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.970 total time=  16.8s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8;, score=0.970 total time=  10.3s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8;, score=0.970 total time=   7.7s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8;, score=0.970 total time=  10.1s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.9;, score=0.970 total time=  10.2s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.9;, score=0.970 total time=   7.6s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.9;, score=0.970 total time=  10.2s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0;, score=0.970 total time=   9.3s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0;, score=0.970 total time=   7.6s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0;, score=0.970 total time=  10.0s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8;, score=0.971 total time=  15.6s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8;, score=0.971 total time=  15.5s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8;, score=0.971 total time=  15.8s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.9;, score=0.971 total time=  15.3s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.9;, score=0.971 total time=  15.4s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.9;, score=0.971 total time=  15.0s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0;, score=0.971 total time=  13.5s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0;, score=0.971 total time=  13.6s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0;, score=0.971 total time=  13.5s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8;, score=0.971 total time=  22.3s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8;, score=0.971 total time=  21.1s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8;, score=0.971 total time=  21.5s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.9;, score=0.971 total time=  20.7s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.9;, score=0.971 total time=  21.1s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.9;, score=0.971 total time=  20.7s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0;, score=0.971 total time=  20.0s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0;, score=0.971 total time=  20.0s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0;, score=0.971 total time=  21.5s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=0.935 total time=   5.1s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=0.934 total time=   7.5s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=0.935 total time=   5.1s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=0.935 total time=   6.1s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=0.934 total time=   5.1s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=0.936 total time=   5.1s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0;, score=0.935 total time=   7.0s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0;, score=0.934 total time=   4.9s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0;, score=0.935 total time=   7.3s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=0.940 total time=   8.9s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=0.939 total time=  10.0s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=0.940 total time=  10.9s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=0.940 total time=   8.5s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=0.940 total time=   8.7s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=0.940 total time=  11.0s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=0.940 total time=   9.5s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=0.939 total time=   8.2s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=0.940 total time=  10.6s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=0.944 total time=  14.8s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=0.944 total time=  14.6s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=0.944 total time=  14.5s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9;, score=0.944 total time=  14.3s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9;, score=0.944 total time=  14.4s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9;, score=0.944 total time=  14.4s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=0.944 total time=  13.9s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=0.944 total time=  13.8s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=0.944 total time=  13.9s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.954 total time=   6.6s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.954 total time=   7.5s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.954 total time=   6.6s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=0.954 total time=   6.8s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=0.954 total time=   6.5s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=0.954 total time=   6.7s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.954 total time=   6.6s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.954 total time=   6.5s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.954 total time=   8.0s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.957 total time=  11.3s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.957 total time=  11.6s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.957 total time=  13.3s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9;, score=0.957 total time=  13.6s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9;, score=0.957 total time=  13.9s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9;, score=0.957 total time=  13.8s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.957 total time=  13.5s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.957 total time=  13.4s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.957 total time=  13.4s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.960 total time=  19.0s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.960 total time=  21.1s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.960 total time=  18.9s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9;, score=0.960 total time=  18.7s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9;, score=0.961 total time=  20.8s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9;, score=0.960 total time=  18.5s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.960 total time=  18.2s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.960 total time=  19.1s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.960 total time=  18.2s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=0.964 total time=   9.6s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=0.964 total time=   7.8s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=0.964 total time=  10.5s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9;, score=0.964 total time=   9.5s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9;, score=0.964 total time=   8.0s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9;, score=0.964 total time=  10.2s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=0.964 total time=   8.3s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=0.964 total time=   7.6s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=0.964 total time=  10.2s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8;, score=0.966 total time=  16.5s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8;, score=0.966 total time=  16.4s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8;, score=0.965 total time=  16.4s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9;, score=0.966 total time=  16.1s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9;, score=0.965 total time=  14.5s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9;, score=0.965 total time=  15.9s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=0.966 total time=  15.7s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=0.966 total time=  15.9s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=0.965 total time=  16.0s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8;, score=0.967 total time=  25.5s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8;, score=0.967 total time=  22.9s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8;, score=0.967 total time=  23.2s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=0.967 total time=  25.2s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=0.967 total time=  22.8s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=0.967 total time=  22.7s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=0.967 total time=  24.9s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=0.967 total time=  22.0s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=0.967 total time=  23.0s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8;, score=0.956 total time=   5.3s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8;, score=0.956 total time=   5.9s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8;, score=0.956 total time=   5.3s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9;, score=0.956 total time=   7.8s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9;, score=0.956 total time=   5.2s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9;, score=0.956 total time=   7.7s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.956 total time=   5.0s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.956 total time=   5.1s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.956 total time=   5.7s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8;, score=0.962 total time=  10.1s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8;, score=0.962 total time=   8.3s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8;, score=0.962 total time=  11.0s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9;, score=0.962 total time=  10.9s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9;, score=0.962 total time=   8.2s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9;, score=0.962 total time=  10.0s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0;, score=0.961 total time=  10.4s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0;, score=0.962 total time=   8.0s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0;, score=0.961 total time=   9.3s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8;, score=0.964 total time=  14.2s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8;, score=0.965 total time=  14.5s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8;, score=0.964 total time=  14.1s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9;, score=0.964 total time=  14.1s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9;, score=0.964 total time=  14.0s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9;, score=0.964 total time=  14.2s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0;, score=0.964 total time=  14.4s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0;, score=0.964 total time=  13.5s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0;, score=0.964 total time=  13.3s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.967 total time=   6.6s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.967 total time=   9.1s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.967 total time=   6.6s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9;, score=0.967 total time=   7.5s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9;, score=0.967 total time=   6.5s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9;, score=0.967 total time=   7.3s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.967 total time=   6.3s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.967 total time=   7.0s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.966 total time=   6.4s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.969 total time=  11.6s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.969 total time=  13.0s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.969 total time=  13.6s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9;, score=0.969 total time=  13.0s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9;, score=0.969 total time=  13.0s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9;, score=0.969 total time=  13.2s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.969 total time=  12.9s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.969 total time=  12.2s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.969 total time=  10.3s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=0.970 total time=  18.6s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=0.970 total time=  17.6s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=0.970 total time=  17.8s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=0.970 total time=  17.3s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=0.970 total time=  17.6s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=0.970 total time=  17.4s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.970 total time=  16.9s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.970 total time=  16.9s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.970 total time=  16.0s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=0.970 total time=   8.2s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=0.970 total time=  10.6s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=0.970 total time=   8.4s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9;, score=0.970 total time=   7.9s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9;, score=0.970 total time=  10.3s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9;, score=0.970 total time=   7.9s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=0.970 total time=   8.3s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=0.970 total time=  10.2s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=0.970 total time=   7.8s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=0.971 total time=  15.3s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=0.971 total time=  13.9s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=0.971 total time=  14.0s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.9;, score=0.971 total time=  13.9s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.9;, score=0.971 total time=  15.4s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.9;, score=0.971 total time=  15.5s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0;, score=0.971 total time=  15.4s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0;, score=0.971 total time=  15.4s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0;, score=0.971 total time=  15.3s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8;, score=0.971 total time=  21.7s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8;, score=0.971 total time=  21.6s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8;, score=0.971 total time=  22.4s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.9;, score=0.971 total time=  21.0s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.9;, score=0.971 total time=  22.8s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.9;, score=0.971 total time=  20.7s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=0.971 total time=  21.1s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=0.971 total time=  20.3s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=0.971 total time=  20.6s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8;, score=0.962 total time=   5.2s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8;, score=0.962 total time=   5.2s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8;, score=0.962 total time=   6.5s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9;, score=0.962 total time=   5.4s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9;, score=0.962 total time=   7.7s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9;, score=0.962 total time=   5.3s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0;, score=0.962 total time=   6.8s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0;, score=0.962 total time=   5.0s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0;, score=0.962 total time=   5.2s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8;, score=0.966 total time=   9.8s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8;, score=0.966 total time=  11.1s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8;, score=0.966 total time=   9.3s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9;, score=0.966 total time=   8.3s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9;, score=0.966 total time=  10.9s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9;, score=0.966 total time=  10.5s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0;, score=0.966 total time=   8.3s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0;, score=0.966 total time=  10.5s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0;, score=0.966 total time=  10.7s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8;, score=0.967 total time=  13.9s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8;, score=0.967 total time=  13.6s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8;, score=0.967 total time=  14.1s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9;, score=0.967 total time=  13.4s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9;, score=0.967 total time=  12.4s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9;, score=0.967 total time=  11.4s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0;, score=0.967 total time=  11.5s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0;, score=0.967 total time=  13.1s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0;, score=0.967 total time=  13.5s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8;, score=0.969 total time=   9.5s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8;, score=0.969 total time=   6.6s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8;, score=0.969 total time=   8.5s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9;, score=0.969 total time=   6.5s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9;, score=0.969 total time=   7.3s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9;, score=0.969 total time=   6.6s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.969 total time=   7.2s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.969 total time=   6.5s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.969 total time=   6.5s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8;, score=0.970 total time=  13.0s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8;, score=0.970 total time=  13.2s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8;, score=0.970 total time=  13.1s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9;, score=0.970 total time=  12.2s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9;, score=0.970 total time=  10.5s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9;, score=0.970 total time=  11.6s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.970 total time=  12.8s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.970 total time=  12.9s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.970 total time=  12.5s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8;, score=0.971 total time=  17.5s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8;, score=0.971 total time=  17.4s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8;, score=0.971 total time=  18.1s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9;, score=0.971 total time=  17.2s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9;, score=0.971 total time=  17.0s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9;, score=0.971 total time=  17.2s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.971 total time=  16.7s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.971 total time=  15.4s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.971 total time=  16.3s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8;, score=0.971 total time=   7.6s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8;, score=0.971 total time=   9.7s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8;, score=0.971 total time=   9.9s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.9;, score=0.971 total time=   7.6s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.9;, score=0.971 total time=  10.2s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.9;, score=0.971 total time=   9.3s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0;, score=0.971 total time=   7.4s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0;, score=0.971 total time=   9.9s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0;, score=0.971 total time=   7.5s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8;, score=0.971 total time=  13.8s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8;, score=0.971 total time=  13.6s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8;, score=0.971 total time=  13.3s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.9;, score=0.971 total time=  12.9s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.9;, score=0.971 total time=  13.2s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.9;, score=0.971 total time=  13.3s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0;, score=0.971 total time=  12.6s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0;, score=0.971 total time=  13.0s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0;, score=0.971 total time=  13.3s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8;, score=0.971 total time=  21.8s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8;, score=0.971 total time=  21.0s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8;, score=0.971 total time=  21.6s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.9;, score=0.971 total time=  20.8s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.9;, score=0.971 total time=  20.8s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.9;, score=0.971 total time=  20.7s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0;, score=0.972 total time=  19.9s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0;, score=0.972 total time=  19.8s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0;, score=0.971 total time=  22.1s\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.99      0.98   1886055\n",
            "         1.0       0.69      0.50      0.58     95054\n",
            "\n",
            "    accuracy                           0.97   1981109\n",
            "   macro avg       0.83      0.75      0.78   1981109\n",
            "weighted avg       0.96      0.97      0.96   1981109\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1864714   21341]\n",
            " [  47320   47734]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ndcg_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "# \n",
        "train_x = train_data[['']]\n",
        "train_y = train_data['viral']\n",
        "valid_x = valid_data[['']]\n",
        "valid_y = valid_data['viral']\n",
        "test_x = test_data[['']]\n",
        "test_y = test_data['viral']\n",
        "\n",
        "# \n",
        "model1 = xgb.XGBClassifier()\n",
        "\n",
        "# \n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.3, 0.5, 0.7]\n",
        "    }\n",
        "\n",
        "# GridSearchCV\n",
        "grid_search = GridSearchCV(model1, param_grid, scoring='accuracy', cv=3, verbose=3)\n",
        "grid_search.fit(train_x, train_y)\n",
        "\n",
        "# \n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# XGBoost\n",
        "# GridSearchCV\n",
        "model1 = xgb.XGBClassifier(\n",
        "    learning_rate=best_model.learning_rate,\n",
        "    n_estimators=best_model.n_estimators,\n",
        "    max_depth= best_model.max_depth,\n",
        "    subsample=best_model.subsample,\n",
        "    colsample_bytree=best_model.colsample_bytree\n",
        "    )\n",
        "model1.fit(train_x, train_y)\n",
        "\n",
        "# \n",
        "test_pred = model1.predict(test_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jendT_z7NFt-",
        "outputId": "be5ceacb-6611-4ef3-b0c8-5cb007d102b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.99      0.98   1886055\n",
            "         1.0       0.69      0.50      0.58     95054\n",
            "\n",
            "    accuracy                           0.97   1981109\n",
            "   macro avg       0.83      0.75      0.78   1981109\n",
            "weighted avg       0.96      0.97      0.96   1981109\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1864714   21341]\n",
            " [  47320   47734]]\n"
          ]
        }
      ],
      "source": [
        "# accuracy\n",
        "print(\"Classification Report:\\n\", classification_report(test_y, test_pred))\n",
        "conf_matrix = confusion_matrix(test_y, test_pred)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ndcg\n",
        "print(\"NDCG@1:\\n\", ndcg_score(test_y, test_pred, k=1))\n",
        "print(\"NDCG@5:\\n\", ndcg_score(test_y, test_pred, k=5))\n",
        "print(\"NDCG@10:\\n\", ndcg_score(test_y, test_pred, k=10))\n",
        "print(\"NDCG:\\n\", ndcg_score(test_y, test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOQC5mGwNjaM"
      },
      "source": [
        "Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDljE9io3nPE",
        "outputId": "7694cab6-0852-4fdb-9f36-85b4420ad376"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature importances:\n",
            " [('eastmoney_robo_journalism', 0.28605458), ('dominant_topic', 0.25442684), ('article_source_cate', 0.14622656), ('SMA_robo_journalism', 0.12381081), ('media_robo_journalism', 0.0749477), ('exclamation_mark', 0.03831342), ('colon_mark', 0.031960607), ('article_author', 0.022018924), ('month', 0.009027952), ('question_mark', 0.008393501), ('sentiment_score', 0.004819168)]\n"
          ]
        }
      ],
      "source": [
        "# \n",
        "feature_importance = model1.feature_importances_\n",
        "\n",
        "# \n",
        "feature_importance_dict = dict(zip(X1.columns, feature_importance))\n",
        "sorted_feature_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# \n",
        "print(\"Feature importances:\\n\", sorted_feature_importance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkxU6OZiuq2-"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHBdohdxNwjR"
      },
      "source": [
        "Due to network issues, the process of choosing best hyparameters was run in three separate runs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4508Ce0aev-i",
        "outputId": "ca5afeab-592e-46ce-e523-4d649569b219"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing 50 trees with max depth of 10. Mean CV Accuracy: 0.9609995441473013\n",
            "Testing 80 trees with max depth of 10. Mean CV Accuracy: 0.9608366483388011\n",
            "Testing 100 trees with max depth of 10. Mean CV Accuracy: 0.9609056573044837\n",
            "Testing 150 trees with max depth of 10. Mean CV Accuracy: 0.9610417283783352\n",
            "Testing 200 trees with max depth of 10. Mean CV Accuracy: 0.9611682808418918\n",
            "Testing 50 trees with max depth of 20. Mean CV Accuracy: 0.9645174877188216\n",
            "Testing 80 trees with max depth of 20. Mean CV Accuracy: 0.9645678924000126\n",
            "Testing 100 trees with max depth of 20. Mean CV Accuracy: 0.9645996927562314\n",
            "Testing 150 trees with max depth of 20. Mean CV Accuracy: 0.9646053173199325\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# \n",
        "X3 = selected_data\n",
        "y3 = eastmoney['viral']\n",
        "\n",
        "# \n",
        "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.3, random_state=42)\n",
        "\n",
        "# \n",
        "max_depth_options = [10, 20]\n",
        "n_estimators_options = [50, 80, 100, 150, 200]\n",
        "\n",
        "best_score = 0\n",
        "best_params = {'max_depth': None, 'n_estimators': 100}\n",
        "\n",
        "for max_depth in max_depth_options:\n",
        "    for n_estimators in n_estimators_options:\n",
        "        # \n",
        "        model = RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, random_state=42)\n",
        "\n",
        "        # \n",
        "        scores = cross_val_score(model, X3_train, y3_train, cv=5, scoring='accuracy')\n",
        "        average_score = np.mean(scores)\n",
        "\n",
        "        print(f\"Testing {n_estimators} trees with max depth of {max_depth}. Mean CV Accuracy: {average_score}\")\n",
        "\n",
        "        # \n",
        "        if average_score > best_score:\n",
        "            best_score = average_score\n",
        "            best_params = {'max_depth': max_depth, 'n_estimators': n_estimators}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cw5bSbr-uBG-",
        "outputId": "6086f816-777c-4db9-d3fc-82c391d17ac2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing 50 trees with max depth of 30. Mean CV Accuracy: 0.9602871725386375\n",
            "Testing 80 trees with max depth of 30. Mean CV Accuracy: 0.9603044788586083\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# \n",
        "X3 = selected_data\n",
        "y3 = eastmoney['viral']\n",
        "\n",
        "# \n",
        "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.3, random_state=42)\n",
        "\n",
        "# \n",
        "max_depth_options = 30\n",
        "n_estimators_options = [50, 80, 100, 150]\n",
        "\n",
        "best_score = 0\n",
        "best_params = {'max_depth': None, 'n_estimators': 100}\n",
        "\n",
        "for n_estimators in n_estimators_options:\n",
        "    # \n",
        "    model = RandomForestClassifier(max_depth=30, n_estimators=n_estimators, random_state=42)\n",
        "\n",
        "    # \n",
        "    scores = cross_val_score(model, X3_train, y3_train, cv=5, scoring='accuracy')\n",
        "    average_score = np.mean(scores)\n",
        "\n",
        "    print(f\"Testing {n_estimators} trees with max depth of 30. Mean CV Accuracy: {average_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmcqSzbzjFS1",
        "outputId": "f487b6a4-b7ae-4039-e021-974204c8100f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing 100 trees with max depth of 30. Mean CV Accuracy: 0.9603362792253567\n",
            "Testing 150 trees with max depth of 30. Mean CV Accuracy: 0.9603241647952935\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "X3 = selected_data\n",
        "y3 = eastmoney['viral']\n",
        "\n",
        "# \n",
        "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.3, random_state=42)\n",
        "\n",
        "# \n",
        "max_depth_options = 30\n",
        "n_estimators_options = [100, 150]\n",
        "\n",
        "best_score = 0\n",
        "best_params = {'max_depth': None, 'n_estimators': 100}\n",
        "\n",
        "for n_estimators in n_estimators_options:\n",
        "    # \n",
        "    model = RandomForestClassifier(max_depth=30, n_estimators=n_estimators, random_state=42)\n",
        "\n",
        "    # \n",
        "    scores = cross_val_score(model, X3_train, y3_train, cv=5, scoring='accuracy')\n",
        "    average_score = np.mean(scores)\n",
        "\n",
        "    print(f\"Testing {n_estimators} trees with max depth of 30. Mean CV Accuracy: {average_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heYus-N7nVWo",
        "outputId": "4f30de63-75e2-4325-e004-6266f5f6fc18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.97      0.99      0.98   1886055\n",
            "         1.0       0.70      0.46      0.56     95054\n",
            "\n",
            "    accuracy                           0.96   1981109\n",
            "   macro avg       0.84      0.73      0.77   1981109\n",
            "weighted avg       0.96      0.96      0.96   1981109\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1866855   19200]\n",
            " [  50934   44120]]\n"
          ]
        }
      ],
      "source": [
        "# \n",
        "best_model = RandomForestClassifier(max_depth=20, n_estimators=80, random_state=42)\n",
        "best_model.fit(X3_train, y3_train)\n",
        "y3_pred = best_model.predict(X3_test)\n",
        "\n",
        "# \n",
        "print(\"Classification Report:\\n\", classification_report(y3_test, y3_pred))\n",
        "conf_matrix = confusion_matrix(y3_test, y3_pred)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAnSNvrUfGYM",
        "outputId": "3cab5283-40ff-4b6d-8941-c50afca8ce62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature importances:\n",
            " [('article_source_cate', 0.41732270291966256), ('sentiment_score', 0.12940403496400923), ('dominant_topic', 0.12905900539845616), ('article_author', 0.07496864730387429), ('SMA_robo_journalism', 0.05873889168302253), ('media_robo_journalism', 0.050267501669162495), ('month', 0.049556268619000206), ('colon_mark', 0.036353485346739024), ('eastmoney_robo_journalism', 0.03463149453425724), ('exclamation_mark', 0.014866902239271038), ('question_mark', 0.004831065322545256)]\n"
          ]
        }
      ],
      "source": [
        "# \n",
        "feature_importance = best_model.feature_importances_\n",
        "\n",
        "# \n",
        "feature_importance_dict = dict(zip(X3.columns, feature_importance))\n",
        "sorted_feature_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"Feature importances:\\n\", sorted_feature_importance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apgEzYA3BH0i"
      },
      "source": [
        "## LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dp41YRT7SJQ"
      },
      "source": [
        "Add class weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJEIaLrNBNFA",
        "outputId": "c5652f5c-bec4-45f2-82a8-6035d68afcf2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
            "[CV 1/3] END C=9.999999999999999e-05, penalty=l2, solver=liblinear;, score=0.851 total time=  15.7s\n",
            "[CV 2/3] END C=9.999999999999999e-05, penalty=l2, solver=liblinear;, score=0.850 total time=  15.7s\n",
            "[CV 3/3] END C=9.999999999999999e-05, penalty=l2, solver=liblinear;, score=0.850 total time=  15.7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=9.999999999999999e-05, penalty=l2, solver=lbfgs;, score=0.838 total time=  21.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=9.999999999999999e-05, penalty=l2, solver=lbfgs;, score=0.838 total time=  21.9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=9.999999999999999e-05, penalty=l2, solver=lbfgs;, score=0.837 total time=  20.3s\n",
            "[CV 1/3] END C=0.000774263682681127, penalty=l2, solver=liblinear;, score=0.853 total time=  16.2s\n",
            "[CV 2/3] END C=0.000774263682681127, penalty=l2, solver=liblinear;, score=0.853 total time=  16.6s\n",
            "[CV 3/3] END C=0.000774263682681127, penalty=l2, solver=liblinear;, score=0.853 total time=  16.6s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=0.000774263682681127, penalty=l2, solver=lbfgs;, score=0.839 total time=  22.4s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=0.000774263682681127, penalty=l2, solver=lbfgs;, score=0.839 total time=  21.9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=0.000774263682681127, penalty=l2, solver=lbfgs;, score=0.825 total time=  20.7s\n",
            "[CV 1/3] END C=0.005994842503189409, penalty=l2, solver=liblinear;, score=0.852 total time=  16.3s\n",
            "[CV 2/3] END C=0.005994842503189409, penalty=l2, solver=liblinear;, score=0.852 total time=  15.9s\n",
            "[CV 3/3] END C=0.005994842503189409, penalty=l2, solver=liblinear;, score=0.852 total time=  16.3s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=0.005994842503189409, penalty=l2, solver=lbfgs;, score=0.839 total time=  20.8s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=0.005994842503189409, penalty=l2, solver=lbfgs;, score=0.839 total time=  22.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=0.005994842503189409, penalty=l2, solver=lbfgs;, score=0.838 total time=  21.1s\n",
            "[CV 1/3] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=0.852 total time=  16.3s\n",
            "[CV 2/3] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=0.852 total time=  15.9s\n",
            "[CV 3/3] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=0.852 total time=  16.6s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=0.839 total time=  21.6s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=0.831 total time=  20.8s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=0.838 total time=  20.1s\n",
            "[CV 1/3] END C=0.3593813663804626, penalty=l2, solver=liblinear;, score=0.852 total time=  16.6s\n",
            "[CV 2/3] END C=0.3593813663804626, penalty=l2, solver=liblinear;, score=0.852 total time=  15.7s\n",
            "[CV 3/3] END C=0.3593813663804626, penalty=l2, solver=liblinear;, score=0.852 total time=  16.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=0.3593813663804626, penalty=l2, solver=lbfgs;, score=0.839 total time=  19.8s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=0.3593813663804626, penalty=l2, solver=lbfgs;, score=0.839 total time=  21.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=0.3593813663804626, penalty=l2, solver=lbfgs;, score=0.838 total time=  20.1s\n",
            "[CV 1/3] END C=2.782559402207126, penalty=l2, solver=liblinear;, score=0.852 total time=  16.7s\n",
            "[CV 2/3] END C=2.782559402207126, penalty=l2, solver=liblinear;, score=0.852 total time=  15.9s\n",
            "[CV 3/3] END C=2.782559402207126, penalty=l2, solver=liblinear;, score=0.852 total time=  19.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=2.782559402207126, penalty=l2, solver=lbfgs;, score=0.838 total time=  19.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=2.782559402207126, penalty=l2, solver=lbfgs;, score=0.839 total time=  21.2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=2.782559402207126, penalty=l2, solver=lbfgs;, score=0.838 total time=  19.9s\n",
            "[CV 1/3] END C=21.54434690031882, penalty=l2, solver=liblinear;, score=0.852 total time=  16.8s\n",
            "[CV 2/3] END C=21.54434690031882, penalty=l2, solver=liblinear;, score=0.852 total time=  16.0s\n",
            "[CV 3/3] END C=21.54434690031882, penalty=l2, solver=liblinear;, score=0.852 total time=  16.8s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=21.54434690031882, penalty=l2, solver=lbfgs;, score=0.839 total time=  19.9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=21.54434690031882, penalty=l2, solver=lbfgs;, score=0.839 total time=  21.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=21.54434690031882, penalty=l2, solver=lbfgs;, score=0.838 total time=  20.0s\n",
            "[CV 1/3] END C=166.81005372000556, penalty=l2, solver=liblinear;, score=0.852 total time=  16.6s\n",
            "[CV 2/3] END C=166.81005372000556, penalty=l2, solver=liblinear;, score=0.852 total time=  15.8s\n",
            "[CV 3/3] END C=166.81005372000556, penalty=l2, solver=liblinear;, score=0.852 total time=  16.2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=166.81005372000556, penalty=l2, solver=lbfgs;, score=0.839 total time=  19.7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=166.81005372000556, penalty=l2, solver=lbfgs;, score=0.839 total time=  20.8s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=166.81005372000556, penalty=l2, solver=lbfgs;, score=0.838 total time=  20.4s\n",
            "[CV 1/3] END C=1291.5496650148827, penalty=l2, solver=liblinear;, score=0.852 total time=  16.6s\n",
            "[CV 2/3] END C=1291.5496650148827, penalty=l2, solver=liblinear;, score=0.852 total time=  16.0s\n",
            "[CV 3/3] END C=1291.5496650148827, penalty=l2, solver=liblinear;, score=0.852 total time=  16.6s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=1291.5496650148827, penalty=l2, solver=lbfgs;, score=0.839 total time=  19.8s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=1291.5496650148827, penalty=l2, solver=lbfgs;, score=0.839 total time=  21.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=1291.5496650148827, penalty=l2, solver=lbfgs;, score=0.838 total time=  20.5s\n",
            "[CV 1/3] END C=10000.0, penalty=l2, solver=liblinear;, score=0.852 total time=  17.0s\n",
            "[CV 2/3] END C=10000.0, penalty=l2, solver=liblinear;, score=0.852 total time=  16.1s\n",
            "[CV 3/3] END C=10000.0, penalty=l2, solver=liblinear;, score=0.852 total time=  16.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=10000.0, penalty=l2, solver=lbfgs;, score=0.840 total time=  21.4s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=10000.0, penalty=l2, solver=lbfgs;, score=0.839 total time=  22.3s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=10000.0, penalty=l2, solver=lbfgs;, score=0.838 total time=  21.6s\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "selected_data = eastmoney[columns]\n",
        "selected_data.columns = selected_data.columns.str.strip()\n",
        "\n",
        "#  dominant_topic \n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "dominant_topic_encoded = encoder.fit_transform(selected_data[['dominant_topic']])\n",
        "encoded_df = pd.DataFrame(dominant_topic_encoded, columns=[f\"topic_{i}\" for i in range(dominant_topic_encoded.shape[1])])\n",
        "selected_data = pd.concat([selected_data.drop('dominant_topic', axis=1), encoded_df], axis=1)\n",
        "\n",
        "X2 = selected_data\n",
        "y2 = eastmoney['viral']\n",
        "\n",
        "# \n",
        "scaler = StandardScaler()\n",
        "sentiment_scores = X2['sentiment_score'].values.reshape(-1, 1)\n",
        "X2['sentiment_score'] = scaler.fit_transform(sentiment_scores)\n",
        "\n",
        "# \n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.3, random_state=42)\n",
        "\n",
        "# \n",
        "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y2_train), y=y2_train)\n",
        "weights = {i : class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# \n",
        "logistic_model = LogisticRegression(class_weight=weights)\n",
        "\n",
        "# \n",
        "selector = RFE(logistic_model, n_features_to_select=5, step=1)\n",
        "selector.fit(X2_train, y2_train)\n",
        "\n",
        "\n",
        "# \n",
        "param_grid = {\n",
        "    'C': np.logspace(-4, 4, 10),\n",
        "    'penalty': ['l2'],\n",
        "    'solver': ['liblinear', 'lbfgs']\n",
        "}\n",
        "\n",
        "# GridSearchCV\n",
        "grid_search = GridSearchCV(logistic_model, param_grid, cv=3, scoring='accuracy', verbose=3)\n",
        "grid_search.fit(X2_train, y2_train)\n",
        "\n",
        "# \n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# \n",
        "y2_pred = best_model.predict(X2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJ9QalCnwDKu",
        "outputId": "f770840c-21ff-4796-d289-9227cb5f68cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      0.85      0.92   1886055\n",
            "         1.0       0.23      0.91      0.37     95054\n",
            "\n",
            "    accuracy                           0.85   1981109\n",
            "   macro avg       0.61      0.88      0.64   1981109\n",
            "weighted avg       0.96      0.85      0.89   1981109\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1602520  283535]\n",
            " [   8921   86133]]\n"
          ]
        }
      ],
      "source": [
        "# \n",
        "print(\"Classification Report:\\n\", classification_report(y2_test, y2_pred))\n",
        "conf_matrix = confusion_matrix(y2_test, y2_pred)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RVm1BTeOWBQ"
      },
      "source": [
        "Feature importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bk2QBlcWKO9M",
        "outputId": "468d7b8f-9282-4a16-9392-be8ad2babfa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature importances:\n",
            " [('eastmoney_robo_journalism', 1), ('SMA_robo_journalism', 1), ('colon_mark', 1), ('topic_0', 1), ('topic_4', 1), ('topic_3', 2), ('media_robo_journalism', 3), ('topic_2', 4), ('exclamation_mark', 5), ('question_mark', 6), ('topic_1', 7), ('month', 8), ('sentiment_score', 9), ('article_source_cate', 10), ('article_author', 11)]\n"
          ]
        }
      ],
      "source": [
        "feature_importance = list(zip(X2_train.columns, selector.ranking_))\n",
        "feature_importance.sort(key=lambda x: x[1])\n",
        "print(\"Feature importances:\\n\", feature_importance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j52MAhdb7YSV"
      },
      "source": [
        "Without class weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_LFBgK57XvH",
        "outputId": "ed3d901e-4c88-4400-8a1d-29b5428e300e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
            "[CV 1/3] END C=9.999999999999999e-05, penalty=l2, solver=liblinear;, score=0.952 total time=  17.6s\n",
            "[CV 2/3] END C=9.999999999999999e-05, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
            "[CV 3/3] END C=9.999999999999999e-05, penalty=l2, solver=liblinear;, score=0.952 total time=  17.4s\n",
            "[CV 1/3] END C=9.999999999999999e-05, penalty=l2, solver=lbfgs;, score=0.952 total time=  30.7s\n",
            "[CV 2/3] END C=9.999999999999999e-05, penalty=l2, solver=lbfgs;, score=0.952 total time=  51.9s\n",
            "[CV 3/3] END C=9.999999999999999e-05, penalty=l2, solver=lbfgs;, score=0.952 total time= 1.0min\n",
            "[CV 1/3] END C=0.000774263682681127, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
            "[CV 2/3] END C=0.000774263682681127, penalty=l2, solver=liblinear;, score=0.952 total time=  18.6s\n",
            "[CV 3/3] END C=0.000774263682681127, penalty=l2, solver=liblinear;, score=0.952 total time=  18.6s\n",
            "[CV 1/3] END C=0.000774263682681127, penalty=l2, solver=lbfgs;, score=0.952 total time=  56.4s\n",
            "[CV 2/3] END C=0.000774263682681127, penalty=l2, solver=lbfgs;, score=0.952 total time=  29.1s\n",
            "[CV 3/3] END C=0.000774263682681127, penalty=l2, solver=lbfgs;, score=0.952 total time=  47.5s\n",
            "[CV 1/3] END C=0.005994842503189409, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
            "[CV 2/3] END C=0.005994842503189409, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
            "[CV 3/3] END C=0.005994842503189409, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
            "[CV 1/3] END C=0.005994842503189409, penalty=l2, solver=lbfgs;, score=0.953 total time=  55.6s\n",
            "[CV 2/3] END C=0.005994842503189409, penalty=l2, solver=lbfgs;, score=0.953 total time=  52.2s\n",
            "[CV 3/3] END C=0.005994842503189409, penalty=l2, solver=lbfgs;, score=0.952 total time=  27.1s\n",
            "[CV 1/3] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
            "[CV 2/3] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
            "[CV 3/3] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
            "[CV 1/3] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=0.953 total time= 1.6min\n",
            "[CV 2/3] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=0.953 total time=  50.4s\n",
            "[CV 3/3] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=0.952 total time=  43.2s\n",
            "[CV 1/3] END C=0.3593813663804626, penalty=l2, solver=liblinear;, score=0.952 total time=  18.6s\n",
            "[CV 2/3] END C=0.3593813663804626, penalty=l2, solver=liblinear;, score=0.952 total time=  18.6s\n",
            "[CV 3/3] END C=0.3593813663804626, penalty=l2, solver=liblinear;, score=0.952 total time=  18.4s\n",
            "[CV 1/3] END C=0.3593813663804626, penalty=l2, solver=lbfgs;, score=0.952 total time=  37.6s\n",
            "[CV 2/3] END C=0.3593813663804626, penalty=l2, solver=lbfgs;, score=0.952 total time=  25.6s\n",
            "[CV 3/3] END C=0.3593813663804626, penalty=l2, solver=lbfgs;, score=0.952 total time=  28.6s\n",
            "[CV 1/3] END C=2.782559402207126, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
            "[CV 2/3] END C=2.782559402207126, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
            "[CV 3/3] END C=2.782559402207126, penalty=l2, solver=liblinear;, score=0.952 total time=  18.3s\n",
            "[CV 1/3] END C=2.782559402207126, penalty=l2, solver=lbfgs;, score=0.953 total time=  54.8s\n",
            "[CV 2/3] END C=2.782559402207126, penalty=l2, solver=lbfgs;, score=0.953 total time= 1.1min\n",
            "[CV 3/3] END C=2.782559402207126, penalty=l2, solver=lbfgs;, score=0.952 total time=  37.0s\n",
            "[CV 1/3] END C=21.54434690031882, penalty=l2, solver=liblinear;, score=0.952 total time=  18.6s\n",
            "[CV 2/3] END C=21.54434690031882, penalty=l2, solver=liblinear;, score=0.952 total time=  18.6s\n",
            "[CV 3/3] END C=21.54434690031882, penalty=l2, solver=liblinear;, score=0.952 total time=  18.6s\n",
            "[CV 1/3] END C=21.54434690031882, penalty=l2, solver=lbfgs;, score=0.952 total time= 1.5min\n",
            "[CV 2/3] END C=21.54434690031882, penalty=l2, solver=lbfgs;, score=0.953 total time=  38.5s\n",
            "[CV 3/3] END C=21.54434690031882, penalty=l2, solver=lbfgs;, score=0.953 total time=  55.5s\n",
            "[CV 1/3] END C=166.81005372000556, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
            "[CV 2/3] END C=166.81005372000556, penalty=l2, solver=liblinear;, score=0.952 total time=  18.3s\n",
            "[CV 3/3] END C=166.81005372000556, penalty=l2, solver=liblinear;, score=0.952 total time=  18.4s\n",
            "[CV 1/3] END C=166.81005372000556, penalty=l2, solver=lbfgs;, score=0.952 total time=  20.9s\n",
            "[CV 2/3] END C=166.81005372000556, penalty=l2, solver=lbfgs;, score=0.952 total time=  32.8s\n",
            "[CV 3/3] END C=166.81005372000556, penalty=l2, solver=lbfgs;, score=0.953 total time= 1.2min\n",
            "[CV 1/3] END C=1291.5496650148827, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
            "[CV 2/3] END C=1291.5496650148827, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
            "[CV 3/3] END C=1291.5496650148827, penalty=l2, solver=liblinear;, score=0.952 total time=  18.6s\n",
            "[CV 1/3] END C=1291.5496650148827, penalty=l2, solver=lbfgs;, score=0.953 total time=  45.2s\n",
            "[CV 2/3] END C=1291.5496650148827, penalty=l2, solver=lbfgs;, score=0.953 total time=  48.1s\n",
            "[CV 3/3] END C=1291.5496650148827, penalty=l2, solver=lbfgs;, score=0.952 total time= 2.3min\n",
            "[CV 1/3] END C=10000.0, penalty=l2, solver=liblinear;, score=0.952 total time=  18.2s\n",
            "[CV 2/3] END C=10000.0, penalty=l2, solver=liblinear;, score=0.952 total time=  18.3s\n",
            "[CV 3/3] END C=10000.0, penalty=l2, solver=liblinear;, score=0.952 total time=  18.4s\n",
            "[CV 1/3] END C=10000.0, penalty=l2, solver=lbfgs;, score=0.952 total time=  22.6s\n",
            "[CV 2/3] END C=10000.0, penalty=l2, solver=lbfgs;, score=0.953 total time= 1.1min\n",
            "[CV 3/3] END C=10000.0, penalty=l2, solver=lbfgs;, score=0.952 total time=  19.8s\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "selected_data = eastmoney[columns]\n",
        "selected_data.columns = selected_data.columns.str.strip()\n",
        "\n",
        "#  dominant_topic \n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "dominant_topic_encoded = encoder.fit_transform(selected_data[['dominant_topic']])\n",
        "encoded_df = pd.DataFrame(dominant_topic_encoded, columns=[f\"topic_{i}\" for i in range(dominant_topic_encoded.shape[1])])\n",
        "selected_data = pd.concat([selected_data.drop('dominant_topic', axis=1), encoded_df], axis=1)\n",
        "\n",
        "X2 = selected_data\n",
        "y2 = eastmoney['viral']\n",
        "\n",
        "# \n",
        "scaler = StandardScaler()\n",
        "sentiment_scores = X2['sentiment_score'].values.reshape(-1, 1)\n",
        "X2['sentiment_score'] = scaler.fit_transform(sentiment_scores)\n",
        "\n",
        "# \n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.3, random_state=42)\n",
        "\n",
        "logistic_model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# \n",
        "selector = RFE(logistic_model, n_features_to_select=5, step=1)\n",
        "selector.fit(X2_train, y2_train)\n",
        "\n",
        "\n",
        "# \n",
        "param_grid = {\n",
        "    'C': np.logspace(-4, 4, 10),\n",
        "    'penalty': ['l2'],\n",
        "    'solver': ['liblinear', 'lbfgs']\n",
        "}\n",
        "\n",
        "# GridSearchCV\n",
        "grid_search = GridSearchCV(logistic_model, param_grid, cv=3, scoring='accuracy', verbose=3)\n",
        "grid_search.fit(X2_train, y2_train)\n",
        "\n",
        "# \n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# \n",
        "y2_pred = best_model.predict(X2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaKLpSD17XrT",
        "outputId": "bb38aaf5-a66c-4d44-ed6c-e0d3ca2b74d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.95      1.00      0.98   1886055\n",
            "         1.0       0.55      0.04      0.07     95054\n",
            "\n",
            "    accuracy                           0.95   1981109\n",
            "   macro avg       0.75      0.52      0.52   1981109\n",
            "weighted avg       0.93      0.95      0.93   1981109\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1883050    3005]\n",
            " [  91393    3661]]\n"
          ]
        }
      ],
      "source": [
        "# \n",
        "print(\"Classification Report:\\n\", classification_report(y2_test, y2_pred))\n",
        "conf_matrix = confusion_matrix(y2_test, y2_pred)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YrxF0-9OgSq"
      },
      "source": [
        "Feature importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLegJxIh8HKd",
        "outputId": "0d91df3b-f329-4bc9-ebab-8df7044ee8ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature importances:\n",
            " [('eastmoney_robo_journalism', 1), ('SMA_robo_journalism', 1), ('colon_mark', 1), ('topic_3', 1), ('topic_4', 1), ('topic_0', 2), ('media_robo_journalism', 3), ('topic_1', 4), ('question_mark', 5), ('topic_2', 6), ('exclamation_mark', 7), ('sentiment_score', 8), ('month', 9), ('article_source_cate', 10), ('article_author', 11)]\n"
          ]
        }
      ],
      "source": [
        "feature_importance = list(zip(X2_train.columns, selector.ranking_))\n",
        "feature_importance.sort(key=lambda x: x[1])\n",
        "print(\"Feature importances:\\n\", feature_importance)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "haMqQXwegh7q",
        "toZxlWepyRVA",
        "xxQblqMLVcsU",
        "iPW1-BTAuf_B"
      ],
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
