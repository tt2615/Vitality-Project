{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EisemHaEHPmR",
    "outputId": "4d1bf0bc-380b-42fd-b872-76b6883c07a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EFI1I2WoeEuL",
    "outputId": "081a4f79-91c6-4ae4-a9c7-63cef44d328f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-aea18ec24f7a>:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  eastmoney = pd.read_csv('/content/drive/MyDrive/eastmoney_data_senti.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "eastmoney = pd.read_csv('/content/drive/MyDrive/eastmoney_data_senti.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdy1A0tZVEKW"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wf0UIivvdUtD"
   },
   "outputs": [],
   "source": [
    "eastmoney.fillna('0', inplace=True)\n",
    "\n",
    "# 对article_source进行分类\n",
    "# 将含有东方财富的归为一类\n",
    "# 将含有choice的归位一类\n",
    "\n",
    "def categorize_source(source):\n",
    "    source = str(source)\n",
    "    if '东方财富' in source:\n",
    "        return '东方财富'\n",
    "    elif 'Choice数据' in source:\n",
    "        return 'Choice数据'\n",
    "    else:\n",
    "        return source\n",
    "\n",
    "# 变为category类\n",
    "eastmoney['article_source_cate'] = eastmoney['article_source_cate'].astype('category')\n",
    "unique_values = eastmoney['article_source_cate'].unique()\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qR3YpKUZeVZr",
    "outputId": "8c336109-4185-40d1-fa07-b77fd6f80d22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting snownlp\n",
      "  Downloading snownlp-0.12.3.tar.gz (37.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: snownlp\n",
      "  Building wheel for snownlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for snownlp: filename=snownlp-0.12.3-py3-none-any.whl size=37760946 sha256=625a578124dfb7a07a419690ed3f1e52b1b4129b87519b0a442a37d17f6de6dc\n",
      "  Stored in directory: /root/.cache/pip/wheels/43/f3/70/8990fc249efeb396007766676706f71dd3d1ca3c023ce522ce\n",
      "Successfully built snownlp\n",
      "Installing collected packages: snownlp\n",
      "Successfully installed snownlp-0.12.3\n"
     ]
    }
   ],
   "source": [
    "!pip install snownlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QNPTVAqPjMMv"
   },
   "source": [
    "#Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1tnQLzCejRxb"
   },
   "outputs": [],
   "source": [
    "sentiment_dict = {}\n",
    "with open('media_sentiment_score.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) == 2:\n",
    "            word, score = parts\n",
    "            sentiment_dict[word] = float(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WjGAGTkHdbJE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "from snownlp import SnowNLP\n",
    "from collections import Counter\n",
    "\n",
    "def analyze_sentiment(title, sentiment_dict):\n",
    "    words = jieba.lcut(title)\n",
    "    # 计算情感得分\n",
    "    score = 0\n",
    "    for word in words:\n",
    "        if word in sentiment_dict:\n",
    "            # 使用自定义词典的得分\n",
    "            score += sentiment_dict[word]\n",
    "        else:\n",
    "            # 使用SnowNLP的情感得分并转换范围到-1到1\n",
    "            snownlp_score = SnowNLP(word).sentiments\n",
    "            adjusted_score = snownlp_score * 2 - 1\n",
    "            score += adjusted_score\n",
    "    # 标准化得分\n",
    "    normalized_score = score / len(words)\n",
    "    return normalized_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "id": "Npvb7yNMd-2m",
    "outputId": "0408766e-0a76-4310-dbce-e2d67c80a3ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "DEBUG:jieba:Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "DEBUG:jieba:Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 5.007 seconds.\n",
      "DEBUG:jieba:Loading model cost 5.007 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "DEBUG:jieba:Prefix dict has been built successfully.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-cd4fca60b8c0>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem_titles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# 使用jieba进行分词并过滤非字母字符\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjieba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 进行词频统计\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jieba/__init__.py\u001b[0m in \u001b[0;36mlcut\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlcut_for_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jieba/__init__.py\u001b[0m in \u001b[0;36mcut\u001b[0;34m(self, sentence, cut_all, HMM, use_paddle)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mre_han\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcut_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jieba/__init__.py\u001b[0m in \u001b[0;36m__cut_DAG\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mDAG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_DAG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mroute\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDAG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jieba/__init__.py\u001b[0m in \u001b[0;36mcalc\u001b[0;34m(self, sentence, DAG, route)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mlogtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             route[idx] = max((log(self.FREQ.get(sentence[idx:x + 1]) or 1) -\n\u001b[0m\u001b[1;32m    178\u001b[0m                               logtotal + route[x + 1][0], x) for x in DAG[idx])\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jieba/__init__.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mlogtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             route[idx] = max((log(self.FREQ.get(sentence[idx:x + 1]) or 1) -\n\u001b[0m\u001b[1;32m    178\u001b[0m                               logtotal + route[x + 1][0], x) for x in DAG[idx])\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#词频统计\n",
    "item_titles = eastmoney['item_title'].dropna().tolist()\n",
    "words = []\n",
    "for title in item_titles:\n",
    "    # 使用jieba进行分词并过滤非字母字符\n",
    "    words.extend([word for word in jieba.lcut(title) if word.isalpha()])\n",
    "\n",
    "# 进行词频统计\n",
    "word_freq = Counter(words)\n",
    "print(word_freq.most_common(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2l5qDHoAdzbC"
   },
   "outputs": [],
   "source": [
    "# 计算每个标题的情感得分并创建新列\n",
    "eastmoney['sentiment_score'] = eastmoney['item_title'].apply(analyze_sentiment, sentiment_dict= sentiment_dict)\n",
    "\n",
    "# 查看带有情感得分的DataFrame6\n",
    "print(eastmoney['sentiment_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pg0-YEiTd2I5"
   },
   "outputs": [],
   "source": [
    "# 统计每个情感得分的频率\n",
    "sentiment_counts = eastmoney['sentiment_score'].value_counts()\n",
    "\n",
    "# 打印得分的统计情况\n",
    "print(sentiment_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_15aALbXT5iV"
   },
   "source": [
    "# Sentiment analysis(drop stopwords to caculate the score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uHVndC9SUhUE"
   },
   "outputs": [],
   "source": [
    "def load_stopwords(filepath):\n",
    "    stopwords = set()  # 使用set来存储停用词，避免重复且提高查找效率\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            stopwords.add(line.strip())\n",
    "    return stopwords\n",
    "\n",
    "stopwords = load_stopwords('/content/hit_stopwords.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CS0qpLllT97q"
   },
   "outputs": [],
   "source": [
    "sentiment_dict = {}\n",
    "with open('media_sentiment_score.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) == 2:\n",
    "            word, score = parts\n",
    "            sentiment_dict[word] = float(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FWvTApCfUq7G"
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import re\n",
    "\n",
    "# 去除文本中的标点符号\n",
    "def remove_punctuation(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# 去除停用词\n",
    "def remove_stopwords(text, stopwords):\n",
    "    words = jieba.cut(text)\n",
    "    words_filtered = [word for word in words if word not in stopwords]\n",
    "    return ' '.join(words_filtered)  # 返回分词后的字符串，词之间以空格分隔\n",
    "\n",
    "# 预处理文本，包括去除标点和停用词\n",
    "def preprocess_text(text, stopwords):\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_stopwords(text, stopwords)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I8AyhllHYY6f",
    "outputId": "1d1fbe6a-6dbf-4924-f42f-3ba5eeaf6fde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting snownlp\n",
      "  Downloading snownlp-0.12.3.tar.gz (37.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: snownlp\n",
      "  Building wheel for snownlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for snownlp: filename=snownlp-0.12.3-py3-none-any.whl size=37760946 sha256=dec6703cee9f16e7b789f327d4808436c308d7515635794e8113e97c5f3a9d3c\n",
      "  Stored in directory: /root/.cache/pip/wheels/43/f3/70/8990fc249efeb396007766676706f71dd3d1ca3c023ce522ce\n",
      "Successfully built snownlp\n",
      "Installing collected packages: snownlp\n",
      "Successfully installed snownlp-0.12.3\n"
     ]
    }
   ],
   "source": [
    "pip install snownlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yM9eoU0mU3Eb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "from snownlp import SnowNLP\n",
    "from collections import Counter\n",
    "\n",
    "def analyze_sentiment(title, stopwords, sentiment_dict):\n",
    "    title = preprocess_text(title, stopwords)  # 预处理标题\n",
    "    words = jieba.lcut(title)  # 再次分词\n",
    "    score = 0\n",
    "    for word in words:\n",
    "        if word in sentiment_dict:\n",
    "            score += sentiment_dict[word]\n",
    "        else:\n",
    "            snownlp_score = SnowNLP(word).sentiments\n",
    "            adjusted_score = snownlp_score * 2 - 1\n",
    "            score += adjusted_score\n",
    "    normalized_score = score / len(words) if words else 0  # 防止除以零错误\n",
    "    return normalized_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3KQjJazcU9pz"
   },
   "outputs": [],
   "source": [
    "# 计算每个标题的情感得分并创建新列\n",
    "eastmoney['drop_sentiment_score'] = eastmoney['item_title'].apply(lambda x: analyze_sentiment(x, stopwords, sentiment_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "toSnTNhNMeai"
   },
   "source": [
    "Compare the score of original sentiment score with score dropping the stopwords. The result of original one looks good. So use the sentiment score in the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUZNRLvmaN5a",
    "outputId": "833d1842-51a9-4c14-ffd7-54830aa0c30b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              item_title  sentiment_score  \\\n",
      "6082451        九安医疗董事长回应兜底增持：对公司未来长期发展坚定         0.432288   \n",
      "4962086              新洁能07月14日被沪股通减持33万股        -0.176380   \n",
      "712516          英科医疗11月10日被深股通减持171.29万股        -0.210590   \n",
      "5884660            中富通2018年度净利润预增25%-50%        -0.037155   \n",
      "1293733   招商证券：主力资金连续6天净流出累计2.46亿元（12-16         0.006954   \n",
      "5249615   哈铁科技：融资净偿还79.7万元，融资余额4233.93万元         0.156243   \n",
      "2431342   齐心集团：融资净买入143.75万元，融资余额1.83亿元（         0.246737   \n",
      "2621497        青农商行(002958)融资融券信息(03-02)         0.039410   \n",
      "4137228      【图解季报】抚顺特钢：2021年一季度归母净利润同比大         0.118083   \n",
      "6426472                  长安信托产品逾期 恒银科技踩雷         0.284918   \n",
      "4520774  广深铁路：连续7日融资净买入累计2127.57万元（01-11         0.164345   \n",
      "6195490        瑞茂通：公司开展的生物柴油业务主要销往荷兰等欧洲国         0.078935   \n",
      "3626251         章源钨业（002378）龙虎榜数据（04-08）         0.103458   \n",
      "270392         国信证券首次给予报喜鸟买入评级 目标价5.6~6元         0.123501   \n",
      "253464      东港股份本周融资净买入805.29万元，居造纸印刷板块第         0.164250   \n",
      "217472      达安基因本周融资净偿还3919.86万元，居医疗器械板块         0.093809   \n",
      "5112518   万德斯：连续7日融资净偿还累计304.17万元（10-15）        -0.013049   \n",
      "419831   金溢科技：主力资金净流出659.62万元，净占比-7.46%（         0.116400   \n",
      "4778372     浙江鼎力股东户数下降2.04%，户均持股100.74万元        -0.023510   \n",
      "5545315      所出具的獐子岛2016年年审报告存虚假记载 大华所被罚        -0.000410   \n",
      "\n",
      "         drop_sentiment_score  \n",
      "6082451              0.287594  \n",
      "4962086             -0.080024  \n",
      "712516              -0.097852  \n",
      "5884660             -0.007874  \n",
      "1293733              0.016225  \n",
      "5249615              0.116709  \n",
      "2431342              0.166107  \n",
      "2621497              0.081907  \n",
      "4137228              0.096211  \n",
      "6426472              0.175529  \n",
      "4520774              0.122333  \n",
      "6195490              0.070112  \n",
      "3626251              0.100069  \n",
      "270392               0.133229  \n",
      "253464               0.120508  \n",
      "217472               0.076090  \n",
      "5112518              0.015402  \n",
      "419831               0.101178  \n",
      "4778372              0.008480  \n",
      "5545315              0.017215  \n"
     ]
    }
   ],
   "source": [
    "#随机查看样本\n",
    "import pandas as pd\n",
    "\n",
    "sampled_data = eastmoney.sample(20, random_state=1)  # 使用random_state确保结果可复现\n",
    "print(sampled_data[['item_title', 'sentiment_score','drop_sentiment_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "6rlrSRvDFRgX",
    "outputId": "2c9fe715-54c8-4089-adb7-c8806720a8d6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#绘制得分结果\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 计算频数\n",
    "score_range = np.arange(-1, 1.01, 0.01)  # 从-1到1，步长为0.01\n",
    "freq, bins = np.histogram(eastmoney['sentiment_score'], bins=score_range)\n",
    "\n",
    "# 绘制折线图\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(bins[:-1], freq, marker='o', linestyle='-', color='b')  # 使用bins的左端点作为x值\n",
    "plt.title('Frequency Distribution of Sentiment Scores')\n",
    "plt.xlabel('Sentiment Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qGtVmgcbL9j3"
   },
   "source": [
    "# Punctuation marks of eastmoney[item_title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vpAsL97_MJ2I"
   },
   "outputs": [],
   "source": [
    "def update_punctuation_marks(eastmoney):\n",
    "    item_title_value = str(eastmoney['item_title'])\n",
    "\n",
    "    #\"！\"\n",
    "    eastmoney['exclamation_mark'] = 1 if '！' in item_title_value else 0\n",
    "\n",
    "    # \"？\"\n",
    "    eastmoney['question_mark'] = 1 if '？' in item_title_value else 0\n",
    "\n",
    "    # \"：\"\n",
    "    eastmoney['colon_mark'] = 1 if '：' in item_title_value else 0\n",
    "\n",
    "update_punctuation_marks(eastmoney)\n",
    "\n",
    "def caculate_punctuation_marks(df):\n",
    "    eastmoney['exclamation_mark'] = eastmoney['item_title'].apply(lambda x: 1 if '！' in x else 0)\n",
    "    eastmoney['question_mark'] = eastmoney['item_title'].apply(lambda x: 1 if '？' in x else 0)\n",
    "    eastmoney['colon_mark'] = eastmoney['item_title'].apply(lambda x: 1 if '：' in x else 0)\n",
    "\n",
    "caculate_punctuation_marks(eastmoney)\n",
    "exclamation_count = eastmoney['exclamation_mark'].sum()\n",
    "question_count = eastmoney['question_mark'].sum()\n",
    "colon_count = eastmoney['colon_mark'].sum()\n",
    "\n",
    "path = '/content/drive/MyDrive/eastmoney_special_symbols.csv'\n",
    "eastmoney.to_csv(path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gMimM5rjP4Kb",
    "outputId": "b76db433-839d-4c9e-ee6a-d9a2bfe11935"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "包含 '！' 的条目数量: 62821\n",
      "包含 '？' 的条目数量: 20609\n",
      "包含 '：' 的条目数量: 3115157\n"
     ]
    }
   ],
   "source": [
    "print(\"包含 '！' 的条目数量:\", exclamation_count)\n",
    "print(\"包含 '？' 的条目数量:\", question_count)\n",
    "print(\"包含 '：' 的条目数量:\", colon_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8hnWeFbVv8U"
   },
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sqBnb8alMyXV"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "eastmoney = pd.read_csv('/content/drive/MyDrive/eastmoney_special_symbols.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uhJwJMgJM7RO",
    "outputId": "ccefddc5-1a12-4cf6-c0ea-3d223712a637"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['item_title', 'item_author', 'article_author', 'article_source',\n",
      "       'item_views', 'item_comment_counts', 'article_likes', 'year', 'month',\n",
      "       'eastmoney_robo_journalism', 'media_robo_journalism',\n",
      "       'SMA_robo_journalism', 'viral', 'article_source_cate',\n",
      "       'item_author_cate', 'sentiment_score', 'drop_sentiment_score',\n",
      "       'exclamation_mark', 'question_mark', 'colon_mark'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(eastmoney.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DmRYfCoDMxoC"
   },
   "source": [
    "Lda model with num_topics=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uz1aEzQtSkPs",
    "outputId": "1050e788-ef07-464a-c1a4-b8fbc4fabbb4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "DEBUG:jieba:Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "DEBUG:jieba:Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.839 seconds.\n",
      "DEBUG:jieba:Loading model cost 0.839 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "DEBUG:jieba:Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "from gensim import corpora, models\n",
    "import re\n",
    "\n",
    "# 去除文本中的标点符号\n",
    "def remove_punctuation(text):\n",
    "    # 使用正则表达式去除标点\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# 加载停用词列表\n",
    "stop_words = set()\n",
    "with open('hit_stopwords.txt', 'r', encoding='utf-8') as file:  # 假设停用词列表文件名为 chinese_stop_words.txt\n",
    "    for word in file:\n",
    "        stop_words.add(word.strip())\n",
    "def remove_stopwords(words):\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    return words\n",
    "\n",
    "# eastmoney['sentiment_score'] 为情感得分列\n",
    "# 分词处理\n",
    "eastmoney['cut_titles'] = eastmoney['item_title'].apply(lambda x: remove_stopwords(list(jieba.cut(remove_punctuation(x)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AhP6HKYZDlXU"
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "import re\n",
    "# 创建词典（即单词的唯一ID映射）\n",
    "dictionary = corpora.Dictionary(eastmoney['cut_titles'])\n",
    "# 使用词典将文档转换成文档-词矩阵（bag-of-words）\n",
    "corpus = [dictionary.doc2bow(text) for text in eastmoney['cut_titles']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ujaiSgrnLA77"
   },
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "# 加载保存的模型\n",
    "model_path = '/content/drive/MyDrive/lda/eastmoney_lda_model5'\n",
    "lda_model = models.LdaModel.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D1htNVnaZoyw",
    "outputId": "ae748ecd-10ee-41cc-8008-f8d7bf83d1be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.070*\"万股\" + 0.068*\"股通\" + 0.040*\"增持\" + 0.031*\"减持\" + 0.029*\"沪\" + 0.022*\"获深\" + 0.019*\"快速\" + 0.019*\"股份\" + 0.017*\"5\" + 0.016*\"深\"')\n",
      "(1, '0.050*\"净\" + 0.046*\"主力\" + 0.045*\"资金\" + 0.045*\"本周\" + 0.036*\"居\" + 0.030*\"流出\" + 0.025*\"板块\" + 0.025*\"占\" + 0.021*\"连续\" + 0.018*\"累计\"')\n",
      "(2, '0.159*\"融资\" + 0.096*\"净\" + 0.061*\"余额\" + 0.054*\"买入\" + 0.050*\"偿还\" + 0.026*\"连续\" + 0.024*\"累计\" + 0.012*\"3\" + 0.012*\"科技\" + 0.010*\"回顾\"')\n",
      "(3, '0.110*\"融资\" + 0.051*\"信息\" + 0.050*\"融券\" + 0.035*\"余额\" + 0.024*\"股份\" + 0.021*\"净\" + 0.021*\"创近\" + 0.020*\"一年\" + 0.017*\"新低\" + 0.016*\"偿还\"')\n",
      "(4, '0.046*\" \" + 0.019*\"净利润\" + 0.016*\"公司\" + 0.015*\"同比\" + 0.015*\"股份\" + 0.011*\"股东\" + 0.008*\"2021\" + 0.008*\"预计\" + 0.008*\"证券\" + 0.008*\"科技\"')\n"
     ]
    }
   ],
   "source": [
    "# 打印所有主题\n",
    "topics = lda_model.print_topics(num_words=10)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ziuZm4D9hBGU",
    "outputId": "8f54d7ff-a949-4aee-bf54-c9044b9804ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating topics: 100%|██████████| 6603696/6603696 [10:15:46<00:00, 178.74it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# 如果需要将主题分布加入原DataFrame\n",
    "eastmoney['topics'] = [lda_model[dictionary.doc2bow(text)] for text in tqdm(eastmoney['cut_titles'], desc=\"Calculating topics\")]\n",
    "\n",
    "path = '/content/drive/My Drive/lda/eastmoney_topic_d.csv'\n",
    "eastmoney.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VgUZh6rI0gky",
    "outputId": "75a596cb-93a1-450d-a031-22fc57bb71c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_lda_model.model\t\t      eastmoney_lda_model5.id2word\n",
      "best_lda_model.model.expElogbeta.npy  eastmoney_lda_model5.state\n",
      "best_lda_model.model.id2word\t      eastmoney_special_symbols.csv\n",
      "best_lda_model.model.state\t      eastmoney_topic_d.csv\n",
      "eastmoney_lda_model5\t\t      hit_stopwords.txt\n",
      "eastmoney_lda_model5.expElogbeta.npy  test.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls \"/content/drive/My Drive/lda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MucNKkWNkMhE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "eastmoney = pd.read_csv('/content/drive/MyDrive/lda/eastmoney_topic_d.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_2AFxioKQ08k",
    "outputId": "4ee13d92-d0a2-493e-ee31-5b2118cef86b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['item_title', 'item_author', 'article_author', 'article_source',\n",
      "       'item_views', 'item_comment_counts', 'article_likes', 'year', 'month',\n",
      "       'eastmoney_robo_journalism', 'media_robo_journalism',\n",
      "       'SMA_robo_journalism', 'viral', 'article_source_cate',\n",
      "       'item_author_cate', 'sentiment_score', 'drop_sentiment_score',\n",
      "       'exclamation_mark', 'question_mark', 'colon_mark', 'cut_titles',\n",
      "       'topics'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(eastmoney.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VwqDO3GHRpfz",
    "outputId": "3d77bd4f-cc43-428d-eaa6-5f599ac79997"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    ([(0, 0.9085021), (1, 0.02251449), (2, 0.02262...\n",
      "1    ([(0, 0.022369185), (1, 0.022620665), (2, 0.02...\n",
      "2    ([(0, 0.023687763), (1, 0.48437315), (2, 0.444...\n",
      "3    ([(0, 0.01695534), (1, 0.93128335), (2, 0.0172...\n",
      "4    ([(0, 0.025107827), (1, 0.45474753), (2, 0.469...\n",
      "Name: topics, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(eastmoney['topics'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NkcEt3dpcsV8",
    "outputId": "f5c2aa85-c429-4612-bd29-caf3cf16e8d4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting dominant topics: 100%|██████████| 6603696/6603696 [00:21<00:00, 312198.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             item_title  \\\n",
      "0                    平安银行2019年度10派2.18元   \n",
      "1              平安银行：2020上半年净利润同比下降11.2%   \n",
      "2        平安银行：主力净流入1.05亿元，两市排名第17（09-16   \n",
      "3        平安银行：主力资金连续4天净流入累计4.11亿元（09-17   \n",
      "4        平安银行：主力净流入3.09亿元，两市排名第14（09-18   \n",
      "...                                 ...   \n",
      "6603691       中芯国际今年上半年净利润下降逾五成 半导体市场整体   \n",
      "6603692   中芯国际上半年归母净利润6.34亿美元 同比下降34.1%   \n",
      "6603693    中芯国际上半年营收同比下降13.3% 市场仍处库存消化阶   \n",
      "6603694    中芯国际上半年营收降13%净利降52% 股价涨0.52%   \n",
      "6603695       华为旗舰机“抢跑”刺激消费市场 “晶圆代工双雄”异   \n",
      "\n",
      "                                                    topics  dominant_topic  \n",
      "0        ([(0, 0.9085021), (1, 0.02251449), (2, 0.02262...               0  \n",
      "1        ([(0, 0.022369185), (1, 0.022620665), (2, 0.02...               4  \n",
      "2        ([(0, 0.023687763), (1, 0.48437315), (2, 0.444...               1  \n",
      "3        ([(0, 0.01695534), (1, 0.93128335), (2, 0.0172...               1  \n",
      "4        ([(0, 0.025107827), (1, 0.45474753), (2, 0.469...               2  \n",
      "...                                                    ...             ...  \n",
      "6603691  ([(0, 0.015474596), (1, 0.015493545), (2, 0.01...               4  \n",
      "6603692  ([(0, 0.016933424), (1, 0.016834188), (2, 0.01...               4  \n",
      "6603693  ([(0, 0.01441427), (1, 0.014414503), (2, 0.014...               4  \n",
      "6603694  ([(0, 0.0161588), (1, 0.015602509), (2, 0.0157...               4  \n",
      "6603695  ([(0, 0.022805907), (1, 0.022814138), (2, 0.02...               4  \n",
      "\n",
      "[6603696 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 为每个文档提取最大概率的主题，并加入DataFrame\n",
    "dominant_topics = []\n",
    "for topic_tuple in tqdm(eastmoney['topics'], desc=\"Extracting dominant topics\"):\n",
    "    if topic_tuple:  # 确保topics元组不为空\n",
    "        topic_list = topic_tuple[0]  # 获取主题概率列表\n",
    "        if topic_list:  # 确保主题列表不为空\n",
    "            dominant_topic = max(topic_list, key=lambda x: x[1])[0]\n",
    "            dominant_topics.append(dominant_topic)\n",
    "        else:\n",
    "            dominant_topics.append(None)  # 如果没有主题，则添加None\n",
    "    else:\n",
    "        dominant_topics.append(None)  # 如果topics元组为空，添加None\n",
    "\n",
    "eastmoney['dominant_topic'] = dominant_topics\n",
    "\n",
    "# 查看主题分布在原DataFrame中的样子\n",
    "print(eastmoney[['item_title', 'topics', 'dominant_topic']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UG4It742M82E"
   },
   "source": [
    "# Use machine learning models to predict virality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F4pRYkXe3YpD",
    "outputId": "a827f1e2-92ce-48db-be1b-9bbc56ec119f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "j290P1rx3Mrs"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "eastmoney = pd.read_csv('./data/eastmoney_topic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5IZioREP5Th6",
    "outputId": "ff6c2ef9-879a-4fd9-b8a6-545174c67f63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['item_title', 'item_author', 'article_author', 'article_source',\n",
      "       'item_views', 'item_comment_counts', 'article_likes', 'year', 'month',\n",
      "       'eastmoney_robo_journalism', 'media_robo_journalism',\n",
      "       'SMA_robo_journalism', 'viral', 'article_source_cate',\n",
      "       'item_author_cate', 'sentiment_score', 'drop_sentiment_score',\n",
      "       'exclamation_mark', 'question_mark', 'colon_mark', 'cut_titles',\n",
      "       'topics', 'dominant_topic'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(eastmoney.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0zaowA30uymU"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "# 将类别特征转换为数值\n",
    "le = LabelEncoder()\n",
    "eastmoney['article_author'] = le.fit_transform(eastmoney['article_author'].astype(str))\n",
    "eastmoney['article_source_cate'] = eastmoney['article_source_cate'].astype('category')\n",
    "eastmoney['article_source_cate'] = eastmoney['article_source_cate'].cat.codes\n",
    "eastmoney['dominant_topic'] = eastmoney['dominant_topic'].astype('category')\n",
    "eastmoney['dominant_topic'] = eastmoney['dominant_topic'].cat.codes\n",
    "eastmoney['month'] = eastmoney['month'].astype('category')\n",
    "eastmoney['month'] = eastmoney['month'].cat.codes\n",
    "eastmoney['exclamation_mark'] = eastmoney['exclamation_mark'].astype('category')\n",
    "eastmoney['exclamation_mark'] = eastmoney['exclamation_mark'].cat.codes\n",
    "eastmoney['question_mark'] = eastmoney['question_mark'].astype('category')\n",
    "eastmoney['question_mark'] = eastmoney['question_mark'].cat.codes\n",
    "eastmoney['colon_mark'] = eastmoney['colon_mark'].astype('category')\n",
    "eastmoney['colon_mark'] = eastmoney['colon_mark'].cat.codes\n",
    "columns = ['sentiment_score', 'article_source_cate', 'month', 'eastmoney_robo_journalism',\n",
    "           'media_robo_journalism', 'SMA_robo_journalism', 'article_author', 'dominant_topic',\n",
    "           'exclamation_mark', 'question_mark', 'colon_mark']\n",
    "\n",
    "selected_data = eastmoney[columns]\n",
    "selected_data.columns = selected_data.columns.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iPW1-BTAuf_B"
   },
   "source": [
    "## XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oK8d03bH3jya",
    "outputId": "a231280e-ef5f-4604-a35e-008cd7a2a98c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=0.952 total time=   4.3s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=0.952 total time=   4.0s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=0.952 total time=   3.9s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=0.952 total time=   3.8s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=0.952 total time=   3.8s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=0.952 total time=   3.8s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0;, score=0.952 total time=   3.6s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0;, score=0.952 total time=   3.8s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0;, score=0.952 total time=   3.7s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=0.952 total time=   7.0s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=0.952 total time=   7.0s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=0.952 total time=   7.0s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=0.952 total time=   6.6s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=0.952 total time=   6.7s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=0.952 total time=   6.7s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=0.952 total time=   6.5s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=0.952 total time=   6.4s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=0.952 total time=   6.3s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=0.953 total time=  10.1s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=0.953 total time=   9.9s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=0.953 total time=  10.1s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9;, score=0.953 total time=   9.7s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9;, score=0.953 total time=  10.0s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9;, score=0.953 total time=  10.1s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=0.953 total time=   9.3s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=0.953 total time=   9.3s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=0.953 total time=  10.8s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.952 total time=   5.2s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.952 total time=   5.1s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.952 total time=   5.2s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=0.952 total time=   5.0s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=0.952 total time=   4.9s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=0.952 total time=   4.9s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.952 total time=   4.8s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.952 total time=   4.6s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.952 total time=   4.5s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.952 total time=   8.8s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.952 total time=   8.8s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.952 total time=   9.9s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9;, score=0.952 total time=   9.2s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9;, score=0.952 total time=   9.2s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9;, score=0.952 total time=   9.1s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.952 total time=   9.5s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.952 total time=   9.8s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.952 total time=   9.3s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.953 total time=  13.3s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.953 total time=  13.7s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.953 total time=  13.1s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9;, score=0.953 total time=  13.1s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9;, score=0.953 total time=  13.1s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9;, score=0.953 total time=  12.9s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.953 total time=  12.3s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.953 total time=  21.9s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.953 total time=  18.9s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=0.952 total time=   8.0s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=0.952 total time=   6.9s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=0.952 total time=   8.0s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9;, score=0.952 total time=   6.9s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9;, score=0.952 total time=   6.8s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9;, score=0.952 total time=   6.7s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=0.952 total time=   6.3s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=0.952 total time=   6.2s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=0.952 total time=   6.4s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8;, score=0.953 total time=  12.3s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8;, score=0.953 total time=  12.1s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8;, score=0.953 total time=  12.0s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9;, score=0.953 total time=  12.0s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9;, score=0.953 total time=  12.0s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9;, score=0.953 total time=  12.2s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=0.953 total time=  11.3s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=0.953 total time=  10.8s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=0.953 total time=  10.9s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8;, score=0.953 total time=  16.8s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8;, score=0.953 total time=  16.7s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8;, score=0.953 total time=  17.1s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=0.953 total time=  17.6s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=0.953 total time=  17.5s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=0.953 total time=  17.0s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=0.953 total time=  16.5s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=0.953 total time=  16.3s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=0.953 total time=  16.3s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8;, score=0.956 total time=   4.2s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8;, score=0.956 total time=   4.2s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8;, score=0.956 total time=   4.1s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9;, score=0.956 total time=   4.1s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9;, score=0.956 total time=   4.1s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9;, score=0.955 total time=   4.2s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.956 total time=   4.0s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.956 total time=   3.9s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.956 total time=   3.9s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8;, score=0.960 total time=   7.4s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8;, score=0.960 total time=   7.5s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8;, score=0.960 total time=   7.4s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9;, score=0.960 total time=   7.2s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9;, score=0.960 total time=   7.2s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9;, score=0.960 total time=   7.3s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0;, score=0.960 total time=   6.8s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0;, score=0.960 total time=   6.6s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0;, score=0.960 total time=   6.9s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8;, score=0.961 total time=  10.5s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8;, score=0.961 total time=  10.2s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8;, score=0.961 total time=  10.5s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9;, score=0.961 total time=  10.3s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9;, score=0.961 total time=  10.3s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9;, score=0.961 total time=  10.4s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0;, score=0.961 total time=  10.3s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0;, score=0.961 total time=   9.8s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0;, score=0.961 total time=   9.5s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.962 total time=   5.4s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.962 total time=   5.4s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.962 total time=   5.4s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9;, score=0.962 total time=   5.3s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9;, score=0.962 total time=   5.5s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9;, score=0.962 total time=   5.6s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.962 total time=   5.2s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.962 total time=   5.1s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.962 total time=   6.6s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.963 total time=  10.3s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.963 total time=  10.0s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.963 total time=  10.7s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9;, score=0.963 total time=  15.5s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9;, score=0.963 total time=  12.3s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9;, score=0.963 total time=  10.5s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.963 total time=   9.3s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.963 total time=   9.3s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.963 total time=   9.1s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=0.964 total time=  13.9s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=0.963 total time=  13.7s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=0.964 total time=  14.1s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=0.964 total time=  13.3s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=0.964 total time=  13.7s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=0.964 total time=  13.4s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.964 total time=  13.4s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.964 total time=  13.9s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.964 total time=  13.1s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=0.963 total time=   6.9s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=0.963 total time=   6.8s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=0.963 total time=   6.5s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9;, score=0.963 total time=   6.6s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9;, score=0.963 total time=   6.5s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9;, score=0.963 total time=   6.5s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=0.963 total time=   6.2s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=0.963 total time=   6.3s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=0.963 total time=   6.3s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=0.964 total time=  11.9s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=0.964 total time=  12.9s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=0.964 total time=  12.1s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.9;, score=0.964 total time=  11.7s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.9;, score=0.964 total time=  11.9s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.9;, score=0.964 total time=  11.8s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0;, score=0.964 total time=  11.2s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0;, score=0.964 total time=  11.2s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0;, score=0.964 total time=  11.5s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8;, score=0.964 total time=  17.6s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8;, score=0.964 total time=  17.2s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8;, score=0.964 total time=  17.3s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.9;, score=0.964 total time=  17.3s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.9;, score=0.964 total time=  17.4s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.9;, score=0.964 total time=  17.1s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=0.964 total time=  16.3s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=0.964 total time=  16.5s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=0.964 total time=  16.7s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8;, score=0.961 total time=   4.1s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8;, score=0.961 total time=   4.1s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8;, score=0.961 total time=   4.2s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9;, score=0.960 total time=   4.0s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9;, score=0.960 total time=   3.9s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9;, score=0.960 total time=   4.1s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0;, score=0.961 total time=   4.0s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0;, score=0.960 total time=   3.9s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0;, score=0.961 total time=   3.8s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8;, score=0.962 total time=   7.3s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8;, score=0.962 total time=   7.5s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8;, score=0.962 total time=   8.7s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9;, score=0.962 total time=   9.0s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9;, score=0.962 total time=   7.5s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9;, score=0.962 total time=   7.3s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0;, score=0.962 total time=   6.7s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0;, score=0.962 total time=   7.0s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0;, score=0.962 total time=   7.0s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8;, score=0.963 total time=  10.8s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8;, score=0.963 total time=  11.1s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8;, score=0.963 total time=  11.3s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9;, score=0.962 total time=  10.4s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9;, score=0.963 total time=  10.4s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9;, score=0.963 total time=  10.3s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0;, score=0.963 total time=   9.7s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0;, score=0.963 total time=   9.6s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0;, score=0.963 total time=   9.7s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8;, score=0.963 total time=   5.3s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8;, score=0.963 total time=   5.3s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8;, score=0.963 total time=   5.5s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9;, score=0.963 total time=   5.2s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9;, score=0.963 total time=   5.3s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9;, score=0.963 total time=   5.2s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.963 total time=   5.0s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.963 total time=   5.1s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.963 total time=   5.1s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8;, score=0.964 total time=   9.5s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8;, score=0.964 total time=   9.6s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8;, score=0.964 total time=   9.6s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9;, score=0.964 total time=   9.4s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9;, score=0.964 total time=   9.8s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9;, score=0.964 total time=   9.5s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.964 total time=   8.9s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.964 total time=   9.7s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.964 total time=   9.1s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8;, score=0.964 total time=  13.8s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8;, score=0.964 total time=  14.0s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8;, score=0.964 total time=  13.7s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9;, score=0.964 total time=  14.4s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9;, score=0.964 total time=  13.7s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9;, score=0.964 total time=  13.9s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.964 total time=  13.0s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.964 total time=  13.2s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.964 total time=  13.0s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8;, score=0.964 total time=   6.5s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8;, score=0.964 total time=   6.7s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8;, score=0.964 total time=   7.3s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.9;, score=0.964 total time=   6.7s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.9;, score=0.964 total time=   6.7s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.9;, score=0.964 total time=   6.5s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0;, score=0.964 total time=   6.2s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0;, score=0.964 total time=   6.3s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0;, score=0.964 total time=   6.3s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8;, score=0.964 total time=  12.4s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8;, score=0.964 total time=  12.1s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8;, score=0.964 total time=  11.8s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.9;, score=0.964 total time=  11.8s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.9;, score=0.964 total time=  11.6s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.9;, score=0.964 total time=  11.8s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0;, score=0.964 total time=  11.7s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0;, score=0.964 total time=  11.3s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0;, score=0.964 total time=  11.3s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8;, score=0.965 total time=  17.3s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8;, score=0.964 total time=  17.0s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8;, score=0.965 total time=  18.9s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.9;, score=0.965 total time=  17.4s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.9;, score=0.964 total time=  17.7s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.9;, score=0.965 total time=  17.7s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0;, score=0.965 total time=  16.9s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0;, score=0.964 total time=  16.4s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0;, score=0.965 total time=  16.3s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=0.952 total time=   4.0s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=0.952 total time=   4.0s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=0.952 total time=   4.0s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=0.952 total time=   3.9s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=0.952 total time=   4.3s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=0.952 total time=   4.0s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0;, score=0.952 total time=   3.7s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0;, score=0.952 total time=   3.8s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0;, score=0.952 total time=   3.6s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=0.952 total time=   7.1s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=0.952 total time=   7.1s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=0.952 total time=   7.1s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=0.952 total time=   7.1s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=0.952 total time=   7.0s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=0.952 total time=   6.9s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=0.952 total time=   6.6s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=0.952 total time=   6.6s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=0.952 total time=   6.6s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=0.953 total time=  10.2s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=0.953 total time=  10.7s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=0.953 total time=  10.3s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9;, score=0.953 total time=  10.1s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9;, score=0.953 total time=  10.0s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9;, score=0.953 total time=  10.0s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=0.953 total time=   9.4s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=0.953 total time=   9.4s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=0.953 total time=   9.6s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.952 total time=   5.4s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.952 total time=   5.3s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.952 total time=   5.3s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=0.952 total time=   5.2s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=0.952 total time=   5.3s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=0.952 total time=   5.3s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.952 total time=   5.1s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.952 total time=   5.1s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.952 total time=   5.1s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.953 total time=  10.4s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.953 total time=  10.5s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.953 total time=  10.0s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9;, score=0.953 total time=   9.7s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9;, score=0.953 total time=   9.9s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9;, score=0.953 total time=   9.8s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.953 total time=   9.4s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.953 total time=   9.9s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.953 total time=   9.7s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.957 total time=  15.5s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.957 total time=  15.8s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.957 total time=  15.6s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9;, score=0.957 total time=  15.1s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9;, score=0.957 total time=  15.3s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9;, score=0.957 total time=  15.2s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.957 total time=  14.9s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.957 total time=  15.0s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.957 total time=  14.5s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=0.952 total time=   7.1s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=0.952 total time=   7.1s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=0.952 total time=   6.9s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9;, score=0.952 total time=   6.9s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9;, score=0.952 total time=   6.9s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9;, score=0.952 total time=   7.0s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=0.952 total time=   7.0s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=0.952 total time=   6.7s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=0.952 total time=   7.5s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8;, score=0.954 total time=  13.0s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8;, score=0.954 total time=  12.9s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8;, score=0.954 total time=  12.9s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9;, score=0.954 total time=  12.9s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9;, score=0.954 total time=  12.9s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9;, score=0.954 total time=  12.9s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=0.954 total time=  12.7s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=0.954 total time=  12.2s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=0.954 total time=  12.2s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8;, score=0.961 total time=  19.3s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8;, score=0.961 total time=  19.3s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8;, score=0.961 total time=  19.5s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=0.961 total time=  19.7s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=0.961 total time=  19.9s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=0.961 total time=  19.3s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=0.961 total time=  18.8s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=0.961 total time=  18.7s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=0.961 total time=  18.3s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8;, score=0.958 total time=   4.1s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8;, score=0.957 total time=   4.1s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8;, score=0.958 total time=   4.1s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9;, score=0.958 total time=   4.0s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9;, score=0.958 total time=   4.1s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9;, score=0.958 total time=   4.1s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.958 total time=   3.8s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.958 total time=   3.8s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.958 total time=   3.8s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8;, score=0.961 total time=   7.3s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8;, score=0.961 total time=   7.3s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8;, score=0.961 total time=   7.2s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9;, score=0.961 total time=   7.1s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9;, score=0.961 total time=   7.2s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9;, score=0.961 total time=   7.1s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0;, score=0.961 total time=   6.7s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0;, score=0.961 total time=   6.6s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0;, score=0.961 total time=   7.0s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8;, score=0.962 total time=  10.3s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8;, score=0.962 total time=  10.4s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8;, score=0.962 total time=   9.9s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9;, score=0.962 total time=   9.8s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9;, score=0.962 total time=   9.9s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9;, score=0.962 total time=  10.0s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0;, score=0.962 total time=   9.3s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0;, score=0.962 total time=   9.5s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0;, score=0.962 total time=   9.2s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.962 total time=   5.5s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.963 total time=   5.5s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.962 total time=   5.7s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9;, score=0.962 total time=   5.5s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9;, score=0.963 total time=   5.3s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9;, score=0.963 total time=   5.3s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.962 total time=   5.2s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.963 total time=   5.2s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.962 total time=   5.1s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.964 total time=   9.7s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.964 total time=   9.7s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.964 total time=   9.5s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9;, score=0.964 total time=   9.5s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9;, score=0.964 total time=   9.4s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9;, score=0.964 total time=   9.5s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.964 total time=   8.9s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.964 total time=   9.1s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.964 total time=   9.1s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=0.964 total time=  14.2s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=0.964 total time=  14.0s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=0.964 total time=  13.6s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=0.964 total time=  13.6s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=0.964 total time=  13.5s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=0.964 total time=  13.6s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.964 total time=  12.9s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.964 total time=  12.9s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.964 total time=  13.0s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=0.964 total time=   6.9s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=0.964 total time=   6.9s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=0.964 total time=   6.9s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9;, score=0.964 total time=   6.9s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9;, score=0.964 total time=   7.1s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9;, score=0.964 total time=   6.9s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=0.964 total time=   6.8s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=0.964 total time=   6.7s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=0.964 total time=   7.0s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=0.965 total time=  12.6s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=0.965 total time=  12.6s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=0.965 total time=  12.5s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.9;, score=0.965 total time=  12.5s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.9;, score=0.965 total time=  12.3s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.9;, score=0.965 total time=  12.6s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0;, score=0.965 total time=  12.1s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0;, score=0.965 total time=  12.1s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0;, score=0.965 total time=  12.1s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8;, score=0.965 total time=  18.0s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8;, score=0.965 total time=  18.1s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8;, score=0.965 total time=  18.5s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.9;, score=0.965 total time=  17.7s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.9;, score=0.965 total time=  17.8s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.9;, score=0.965 total time=  17.8s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=0.965 total time=  17.1s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=0.965 total time=  17.1s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=0.965 total time=  17.2s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8;, score=0.961 total time=   4.1s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8;, score=0.962 total time=   4.0s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8;, score=0.960 total time=   3.9s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9;, score=0.962 total time=   4.0s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9;, score=0.962 total time=   3.9s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9;, score=0.961 total time=   3.9s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0;, score=0.962 total time=   3.8s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0;, score=0.962 total time=   3.8s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0;, score=0.961 total time=   3.7s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8;, score=0.963 total time=   6.9s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8;, score=0.963 total time=   6.9s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8;, score=0.963 total time=   7.0s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9;, score=0.963 total time=   6.9s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9;, score=0.963 total time=   6.9s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9;, score=0.963 total time=   6.8s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0;, score=0.963 total time=   6.3s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0;, score=0.963 total time=   6.4s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0;, score=0.963 total time=   6.6s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8;, score=0.963 total time=  10.8s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8;, score=0.963 total time=   9.8s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8;, score=0.963 total time=   9.9s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9;, score=0.963 total time=   9.8s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9;, score=0.963 total time=   9.7s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9;, score=0.963 total time=   9.6s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0;, score=0.963 total time=   9.5s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0;, score=0.963 total time=   9.2s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0;, score=0.963 total time=  10.7s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8;, score=0.964 total time=   5.6s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8;, score=0.964 total time=   5.4s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8;, score=0.964 total time=   5.3s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9;, score=0.964 total time=   5.2s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9;, score=0.964 total time=   5.2s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9;, score=0.964 total time=   5.2s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.964 total time=   4.9s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.964 total time=   5.0s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.964 total time=   5.0s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8;, score=0.965 total time=   9.4s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8;, score=0.964 total time=   9.5s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8;, score=0.964 total time=   9.5s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9;, score=0.964 total time=   9.4s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9;, score=0.964 total time=   9.5s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9;, score=0.964 total time=   9.5s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.965 total time=   9.1s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.964 total time=   8.9s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.964 total time=   8.9s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8;, score=0.965 total time=  13.7s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8;, score=0.964 total time=  13.8s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8;, score=0.965 total time=  13.6s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9;, score=0.965 total time=  13.3s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9;, score=0.964 total time=  13.2s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9;, score=0.965 total time=  13.5s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.965 total time=  12.8s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.964 total time=  12.6s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.965 total time=  12.8s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8;, score=0.965 total time=   6.8s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8;, score=0.964 total time=   6.7s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8;, score=0.965 total time=   6.6s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.9;, score=0.965 total time=   6.6s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.9;, score=0.964 total time=   6.7s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.9;, score=0.965 total time=   6.6s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0;, score=0.965 total time=   6.7s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0;, score=0.964 total time=   6.7s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0;, score=0.964 total time=   6.6s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8;, score=0.965 total time=  12.7s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8;, score=0.965 total time=  12.6s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8;, score=0.965 total time=  12.3s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.9;, score=0.965 total time=  12.2s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.9;, score=0.965 total time=  12.1s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.9;, score=0.965 total time=  12.0s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0;, score=0.965 total time=  11.5s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0;, score=0.965 total time=  11.7s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0;, score=0.965 total time=  11.9s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8;, score=0.965 total time=  17.8s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8;, score=0.965 total time=  18.2s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8;, score=0.965 total time=  17.7s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.9;, score=0.965 total time=  17.6s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.9;, score=0.965 total time=  17.8s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.9;, score=0.965 total time=  17.6s\n",
      "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0;, score=0.965 total time=  16.7s\n",
      "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0;, score=0.965 total time=  16.6s\n",
      "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0;, score=0.965 total time=  16.9s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=0.952 total time=   3.9s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=0.952 total time=   3.9s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=0.952 total time=   3.9s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=0.952 total time=   3.9s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=0.952 total time=   3.9s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=0.952 total time=   3.8s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0;, score=0.952 total time=   3.7s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0;, score=0.952 total time=   3.6s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0;, score=0.952 total time=   3.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=0.952 total time=   7.1s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=0.952 total time=   7.2s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=0.952 total time=   7.0s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=0.952 total time=   7.0s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=0.952 total time=   7.0s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=0.952 total time=   6.9s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=0.952 total time=   6.5s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=0.952 total time=   6.5s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=0.952 total time=   6.4s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=0.953 total time=  10.3s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=0.953 total time=  10.4s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=0.953 total time=  10.4s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9;, score=0.953 total time=  10.0s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9;, score=0.952 total time=  10.2s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9;, score=0.953 total time=  10.1s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=0.953 total time=   9.8s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=0.952 total time=   9.7s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=0.953 total time=  10.0s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.952 total time=   5.4s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.952 total time=   5.4s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.952 total time=   5.3s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=0.952 total time=   5.2s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=0.952 total time=   5.2s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=0.952 total time=   5.1s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.952 total time=   5.1s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.952 total time=   5.0s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.952 total time=   4.9s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.954 total time=  10.1s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.954 total time=   9.9s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.954 total time=  10.1s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9;, score=0.954 total time=   9.8s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9;, score=0.954 total time=   9.7s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9;, score=0.954 total time=   9.8s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.954 total time=   9.3s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.954 total time=   9.5s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.954 total time=   9.4s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.960 total time=  14.9s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.960 total time=  14.6s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.960 total time=  14.6s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9;, score=0.960 total time=  14.7s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9;, score=0.960 total time=  14.5s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9;, score=0.960 total time=  14.6s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.960 total time=  14.4s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.960 total time=  14.1s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.960 total time=  14.0s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=0.952 total time=   6.9s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=0.952 total time=   7.0s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=0.952 total time=   7.0s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9;, score=0.952 total time=   6.9s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9;, score=0.952 total time=   6.7s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9;, score=0.952 total time=   6.8s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=0.952 total time=   6.8s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=0.952 total time=   6.6s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=0.952 total time=   6.5s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8;, score=0.961 total time=  13.1s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8;, score=0.961 total time=  13.4s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8;, score=0.961 total time=  13.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9;, score=0.961 total time=  12.8s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9;, score=0.961 total time=  13.1s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9;, score=0.961 total time=  13.0s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=0.961 total time=  12.7s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=0.961 total time=  12.7s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=0.961 total time=  12.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8;, score=0.963 total time=  20.1s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8;, score=0.963 total time=  19.7s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8;, score=0.963 total time=  19.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=0.963 total time=  19.5s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=0.963 total time=  19.5s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=0.963 total time=  19.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=0.963 total time=  19.3s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=0.963 total time=  19.2s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=0.963 total time=  18.9s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8;, score=0.960 total time=   3.9s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8;, score=0.959 total time=   4.0s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8;, score=0.961 total time=   4.0s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9;, score=0.960 total time=   3.9s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9;, score=0.959 total time=   3.8s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9;, score=0.959 total time=   3.9s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.960 total time=   3.6s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.959 total time=   3.8s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.960 total time=   3.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8;, score=0.962 total time=   6.9s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8;, score=0.962 total time=   7.0s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8;, score=0.962 total time=   7.0s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9;, score=0.962 total time=   6.8s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9;, score=0.962 total time=   6.8s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9;, score=0.961 total time=   6.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0;, score=0.962 total time=   6.4s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0;, score=0.962 total time=   6.4s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0;, score=0.962 total time=   6.3s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8;, score=0.963 total time=  10.0s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8;, score=0.963 total time=  10.1s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8;, score=0.963 total time=   9.9s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9;, score=0.963 total time=   9.7s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9;, score=0.963 total time=   9.7s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9;, score=0.962 total time=   9.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0;, score=0.962 total time=   9.0s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0;, score=0.963 total time=   9.4s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0;, score=0.963 total time=   9.1s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.963 total time=   5.4s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.963 total time=   5.4s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.963 total time=   5.4s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9;, score=0.963 total time=   5.4s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9;, score=0.963 total time=   5.3s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9;, score=0.963 total time=   5.3s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.963 total time=   5.1s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.963 total time=   5.1s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.963 total time=   5.1s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.964 total time=   9.5s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.964 total time=   9.4s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.964 total time=   9.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9;, score=0.964 total time=   9.5s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9;, score=0.964 total time=   9.4s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9;, score=0.964 total time=   9.3s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.964 total time=   9.3s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.964 total time=   9.1s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.964 total time=   9.1s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=0.965 total time=  13.9s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=0.964 total time=  14.0s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=0.964 total time=  13.9s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=0.965 total time=  13.3s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=0.964 total time=  13.6s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=0.964 total time=  13.8s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.965 total time=  13.1s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.964 total time=  13.0s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.964 total time=  12.8s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=0.965 total time=   7.7s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=0.964 total time=   7.4s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=0.965 total time=   7.9s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9;, score=0.965 total time=   8.2s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9;, score=0.964 total time=   7.4s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9;, score=0.965 total time=   7.5s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=0.965 total time=   7.1s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=0.964 total time=   6.9s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=0.965 total time=   6.9s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=0.965 total time=  12.6s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=0.965 total time=  12.4s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=0.965 total time=  12.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.9;, score=0.965 total time=  12.4s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.9;, score=0.965 total time=  12.8s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.9;, score=0.965 total time=  12.5s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0;, score=0.965 total time=  11.9s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0;, score=0.965 total time=  11.7s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0;, score=0.965 total time=  12.0s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8;, score=0.965 total time=  17.8s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8;, score=0.965 total time=  17.9s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8;, score=0.965 total time=  17.9s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.9;, score=0.965 total time=  17.5s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.9;, score=0.965 total time=  17.6s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.9;, score=0.965 total time=  17.5s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=0.965 total time=  17.0s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=0.965 total time=  16.5s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=0.965 total time=  16.9s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8;, score=0.962 total time=   3.9s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8;, score=0.962 total time=   4.0s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8;, score=0.962 total time=   3.8s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9;, score=0.962 total time=   3.8s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9;, score=0.962 total time=   3.8s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9;, score=0.962 total time=   3.8s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0;, score=0.962 total time=   3.6s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0;, score=0.962 total time=   3.7s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0;, score=0.962 total time=   3.6s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8;, score=0.963 total time=   7.0s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8;, score=0.963 total time=   7.0s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8;, score=0.963 total time=   7.1s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9;, score=0.963 total time=   6.8s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9;, score=0.963 total time=   6.8s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9;, score=0.963 total time=   6.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0;, score=0.963 total time=   6.5s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0;, score=0.963 total time=   6.6s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0;, score=0.963 total time=   6.5s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8;, score=0.964 total time=  10.0s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8;, score=0.964 total time=   9.9s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8;, score=0.964 total time=  10.0s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9;, score=0.964 total time=   9.8s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9;, score=0.964 total time=  10.1s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9;, score=0.963 total time=  10.1s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0;, score=0.964 total time=   9.4s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0;, score=0.963 total time=   9.2s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0;, score=0.964 total time=   9.2s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8;, score=0.964 total time=   5.3s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8;, score=0.964 total time=   5.3s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8;, score=0.964 total time=   5.6s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9;, score=0.964 total time=   5.4s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9;, score=0.964 total time=   5.3s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9;, score=0.964 total time=   5.2s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.964 total time=   5.0s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.964 total time=   5.2s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.964 total time=   5.4s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8;, score=0.965 total time=   9.9s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8;, score=0.964 total time=   9.6s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8;, score=0.965 total time=   9.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9;, score=0.965 total time=   9.3s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9;, score=0.964 total time=   9.1s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9;, score=0.965 total time=   9.3s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.965 total time=   8.9s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.964 total time=   8.9s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.965 total time=   8.6s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8;, score=0.965 total time=  13.5s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8;, score=0.965 total time=  13.5s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8;, score=0.965 total time=  13.3s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9;, score=0.965 total time=  13.4s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9;, score=0.965 total time=  13.3s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9;, score=0.965 total time=  13.4s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.965 total time=  12.5s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.965 total time=  12.5s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.965 total time=  12.3s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8;, score=0.965 total time=   6.8s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8;, score=0.965 total time=   6.6s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8;, score=0.965 total time=   6.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.9;, score=0.965 total time=   6.6s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.9;, score=0.965 total time=   6.8s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.9;, score=0.965 total time=   6.5s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0;, score=0.965 total time=   6.4s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0;, score=0.965 total time=   6.5s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0;, score=0.965 total time=   6.4s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8;, score=0.965 total time=  12.0s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8;, score=0.965 total time=  12.0s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8;, score=0.965 total time=  12.1s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.9;, score=0.965 total time=  11.9s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.9;, score=0.965 total time=  11.6s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.9;, score=0.965 total time=  11.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0;, score=0.965 total time=  11.1s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0;, score=0.965 total time=  11.1s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0;, score=0.965 total time=  11.2s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8;, score=0.965 total time=  17.5s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8;, score=0.965 total time=  17.3s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8;, score=0.965 total time=  17.3s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.9;, score=0.965 total time=  17.1s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.9;, score=0.965 total time=  17.0s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.9;, score=0.965 total time=  17.3s\n",
      "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0;, score=0.965 total time=  15.8s\n",
      "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0;, score=0.965 total time=  16.4s\n",
      "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0;, score=0.965 total time=  16.0s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# 划分特征和目标变量\n",
    "X1 = selected_data\n",
    "y1 = eastmoney['viral']\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.3, random_state=42)\n",
    "\n",
    "# 初始化分类器\n",
    "model1 = xgb.XGBClassifier()\n",
    "\n",
    "# 参数网格\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.3, 0.5, 0.7]\n",
    "    }\n",
    "\n",
    "# 设置GridSearchCV\n",
    "grid_search = GridSearchCV(model1, param_grid, scoring='accuracy', cv=3, verbose=3)\n",
    "grid_search.fit(X1_train, y1_train)\n",
    "\n",
    "# 使用最佳参数的模型\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 建立XGBoost模型\n",
    "# 从GridSearchCV获得最佳参数设置\n",
    "model1 = xgb.XGBClassifier(\n",
    "    learning_rate=best_model.learning_rate,\n",
    "    n_estimators=best_model.n_estimators,\n",
    "    max_depth= best_model.max_depth,\n",
    "    subsample=best_model.subsample,\n",
    "    colsample_bytree=best_model.colsample_bytree\n",
    "    )\n",
    "model1.fit(X1_train, y1_train)\n",
    "\n",
    "# 预测\n",
    "y1_pred = model1.predict(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jendT_z7NFt-",
    "outputId": "be5ceacb-6611-4ef3-b0c8-5cb007d102b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.98   1886055\n",
      "         1.0       0.69      0.50      0.58     95054\n",
      "\n",
      "    accuracy                           0.97   1981109\n",
      "   macro avg       0.83      0.75      0.78   1981109\n",
      "weighted avg       0.96      0.97      0.96   1981109\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1864553   21502]\n",
      " [  47089   47965]]\n"
     ]
    }
   ],
   "source": [
    "# 评估\n",
    "print(\"Classification Report:\\n\", classification_report(y1_test, y1_pred))\n",
    "conf_matrix = confusion_matrix(y1_test, y1_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KOQC5mGwNjaM"
   },
   "source": [
    "Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iDljE9io3nPE",
    "outputId": "7694cab6-0852-4fdb-9f36-85b4420ad376"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n",
      " [('eastmoney_robo_journalism', 0.28605458), ('dominant_topic', 0.25442684), ('article_source_cate', 0.14622656), ('SMA_robo_journalism', 0.12381081), ('media_robo_journalism', 0.0749477), ('exclamation_mark', 0.03831342), ('colon_mark', 0.031960607), ('article_author', 0.022018924), ('month', 0.009027952), ('question_mark', 0.008393501), ('sentiment_score', 0.004819168)]\n"
     ]
    }
   ],
   "source": [
    "# 获取特征的重要性\n",
    "feature_importance = model1.feature_importances_\n",
    "\n",
    "# 将特征重要性与特征名称进行配对，并排序\n",
    "feature_importance_dict = dict(zip(X1.columns, feature_importance))\n",
    "sorted_feature_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# 打印特征重要性\n",
    "print(\"Feature importances:\\n\", sorted_feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkxU6OZiuq2-"
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHBdohdxNwjR"
   },
   "source": [
    "Due to network issues, the process of choosing best hyparameters was run in three separate runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4508Ce0aev-i",
    "outputId": "ca5afeab-592e-46ce-e523-4d649569b219"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 50 trees with max depth of 10. Mean CV Accuracy: 0.9609995441473013\n",
      "Testing 80 trees with max depth of 10. Mean CV Accuracy: 0.9608366483388011\n",
      "Testing 100 trees with max depth of 10. Mean CV Accuracy: 0.9609056573044837\n",
      "Testing 150 trees with max depth of 10. Mean CV Accuracy: 0.9610417283783352\n",
      "Testing 200 trees with max depth of 10. Mean CV Accuracy: 0.9611682808418918\n",
      "Testing 50 trees with max depth of 20. Mean CV Accuracy: 0.9645174877188216\n",
      "Testing 80 trees with max depth of 20. Mean CV Accuracy: 0.9645678924000126\n",
      "Testing 100 trees with max depth of 20. Mean CV Accuracy: 0.9645996927562314\n",
      "Testing 150 trees with max depth of 20. Mean CV Accuracy: 0.9646053173199325\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# 数据准备\n",
    "X3 = selected_data\n",
    "y3 = eastmoney['viral']\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.3, random_state=42)\n",
    "\n",
    "# 参数范围设置\n",
    "max_depth_options = [10, 20]\n",
    "n_estimators_options = [50, 80, 100, 150, 200]\n",
    "\n",
    "best_score = 0\n",
    "best_params = {'max_depth': None, 'n_estimators': 100}\n",
    "\n",
    "for max_depth in max_depth_options:\n",
    "    for n_estimators in n_estimators_options:\n",
    "        # 初始化随机森林分类器\n",
    "        model = RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, random_state=42)\n",
    "\n",
    "        # 使用交叉验证计算评分\n",
    "        scores = cross_val_score(model, X3_train, y3_train, cv=5, scoring='accuracy')\n",
    "        average_score = np.mean(scores)\n",
    "\n",
    "        print(f\"Testing {n_estimators} trees with max depth of {max_depth}. Mean CV Accuracy: {average_score}\")\n",
    "\n",
    "        # 检查并更新最佳得分和参数\n",
    "        if average_score > best_score:\n",
    "            best_score = average_score\n",
    "            best_params = {'max_depth': max_depth, 'n_estimators': n_estimators}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cw5bSbr-uBG-",
    "outputId": "6086f816-777c-4db9-d3fc-82c391d17ac2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 50 trees with max depth of 30. Mean CV Accuracy: 0.9602871725386375\n",
      "Testing 80 trees with max depth of 30. Mean CV Accuracy: 0.9603044788586083\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# 数据准备\n",
    "X3 = selected_data\n",
    "y3 = eastmoney['viral']\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.3, random_state=42)\n",
    "\n",
    "# 参数范围设置\n",
    "max_depth_options = 30\n",
    "n_estimators_options = [50, 80, 100, 150]\n",
    "\n",
    "best_score = 0\n",
    "best_params = {'max_depth': None, 'n_estimators': 100}\n",
    "\n",
    "for n_estimators in n_estimators_options:\n",
    "    # 初始化随机森林分类器\n",
    "    model = RandomForestClassifier(max_depth=30, n_estimators=n_estimators, random_state=42)\n",
    "\n",
    "    # 使用交叉验证计算评分\n",
    "    scores = cross_val_score(model, X3_train, y3_train, cv=5, scoring='accuracy')\n",
    "    average_score = np.mean(scores)\n",
    "\n",
    "    print(f\"Testing {n_estimators} trees with max depth of 30. Mean CV Accuracy: {average_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZmcqSzbzjFS1",
    "outputId": "f487b6a4-b7ae-4039-e021-974204c8100f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 100 trees with max depth of 30. Mean CV Accuracy: 0.9603362792253567\n",
      "Testing 150 trees with max depth of 30. Mean CV Accuracy: 0.9603241647952935\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "X3 = selected_data\n",
    "y3 = eastmoney['viral']\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.3, random_state=42)\n",
    "\n",
    "# 参数范围设置\n",
    "max_depth_options = 30\n",
    "n_estimators_options = [100, 150]\n",
    "\n",
    "best_score = 0\n",
    "best_params = {'max_depth': None, 'n_estimators': 100}\n",
    "\n",
    "for n_estimators in n_estimators_options:\n",
    "    # 初始化随机森林分类器\n",
    "    model = RandomForestClassifier(max_depth=30, n_estimators=n_estimators, random_state=42)\n",
    "\n",
    "    # 使用交叉验证计算评分\n",
    "    scores = cross_val_score(model, X3_train, y3_train, cv=5, scoring='accuracy')\n",
    "    average_score = np.mean(scores)\n",
    "\n",
    "    print(f\"Testing {n_estimators} trees with max depth of 30. Mean CV Accuracy: {average_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "heYus-N7nVWo",
    "outputId": "4f30de63-75e2-4325-e004-6266f5f6fc18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.99      0.98   1886055\n",
      "         1.0       0.70      0.46      0.56     95054\n",
      "\n",
      "    accuracy                           0.96   1981109\n",
      "   macro avg       0.84      0.73      0.77   1981109\n",
      "weighted avg       0.96      0.96      0.96   1981109\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1866855   19200]\n",
      " [  50934   44120]]\n"
     ]
    }
   ],
   "source": [
    "# 使用最佳参数训练模型\n",
    "best_model = RandomForestClassifier(max_depth=20, n_estimators=80, random_state=42)\n",
    "best_model.fit(X3_train, y3_train)\n",
    "y3_pred = best_model.predict(X3_test)\n",
    "\n",
    "# 评估\n",
    "print(\"Classification Report:\\n\", classification_report(y3_test, y3_pred))\n",
    "conf_matrix = confusion_matrix(y3_test, y3_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oAnSNvrUfGYM",
    "outputId": "3cab5283-40ff-4b6d-8941-c50afca8ce62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n",
      " [('article_source_cate', 0.41732270291966256), ('sentiment_score', 0.12940403496400923), ('dominant_topic', 0.12905900539845616), ('article_author', 0.07496864730387429), ('SMA_robo_journalism', 0.05873889168302253), ('media_robo_journalism', 0.050267501669162495), ('month', 0.049556268619000206), ('colon_mark', 0.036353485346739024), ('eastmoney_robo_journalism', 0.03463149453425724), ('exclamation_mark', 0.014866902239271038), ('question_mark', 0.004831065322545256)]\n"
     ]
    }
   ],
   "source": [
    "# 获取特征的重要性\n",
    "feature_importance = best_model.feature_importances_\n",
    "\n",
    "# 将特征重要性与特征名称进行配对，并排序\n",
    "feature_importance_dict = dict(zip(X3.columns, feature_importance))\n",
    "sorted_feature_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Feature importances:\\n\", sorted_feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apgEzYA3BH0i"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4dp41YRT7SJQ"
   },
   "source": [
    "Add class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KJEIaLrNBNFA",
    "outputId": "c5652f5c-bec4-45f2-82a8-6035d68afcf2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV 1/3] END C=9.999999999999999e-05, penalty=l2, solver=liblinear;, score=0.851 total time=  15.7s\n",
      "[CV 2/3] END C=9.999999999999999e-05, penalty=l2, solver=liblinear;, score=0.850 total time=  15.7s\n",
      "[CV 3/3] END C=9.999999999999999e-05, penalty=l2, solver=liblinear;, score=0.850 total time=  15.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=9.999999999999999e-05, penalty=l2, solver=lbfgs;, score=0.838 total time=  21.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=9.999999999999999e-05, penalty=l2, solver=lbfgs;, score=0.838 total time=  21.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=9.999999999999999e-05, penalty=l2, solver=lbfgs;, score=0.837 total time=  20.3s\n",
      "[CV 1/3] END C=0.000774263682681127, penalty=l2, solver=liblinear;, score=0.853 total time=  16.2s\n",
      "[CV 2/3] END C=0.000774263682681127, penalty=l2, solver=liblinear;, score=0.853 total time=  16.6s\n",
      "[CV 3/3] END C=0.000774263682681127, penalty=l2, solver=liblinear;, score=0.853 total time=  16.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.000774263682681127, penalty=l2, solver=lbfgs;, score=0.839 total time=  22.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.000774263682681127, penalty=l2, solver=lbfgs;, score=0.839 total time=  21.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.000774263682681127, penalty=l2, solver=lbfgs;, score=0.825 total time=  20.7s\n",
      "[CV 1/3] END C=0.005994842503189409, penalty=l2, solver=liblinear;, score=0.852 total time=  16.3s\n",
      "[CV 2/3] END C=0.005994842503189409, penalty=l2, solver=liblinear;, score=0.852 total time=  15.9s\n",
      "[CV 3/3] END C=0.005994842503189409, penalty=l2, solver=liblinear;, score=0.852 total time=  16.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.005994842503189409, penalty=l2, solver=lbfgs;, score=0.839 total time=  20.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.005994842503189409, penalty=l2, solver=lbfgs;, score=0.839 total time=  22.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.005994842503189409, penalty=l2, solver=lbfgs;, score=0.838 total time=  21.1s\n",
      "[CV 1/3] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=0.852 total time=  16.3s\n",
      "[CV 2/3] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=0.852 total time=  15.9s\n",
      "[CV 3/3] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=0.852 total time=  16.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=0.839 total time=  21.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=0.831 total time=  20.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=0.838 total time=  20.1s\n",
      "[CV 1/3] END C=0.3593813663804626, penalty=l2, solver=liblinear;, score=0.852 total time=  16.6s\n",
      "[CV 2/3] END C=0.3593813663804626, penalty=l2, solver=liblinear;, score=0.852 total time=  15.7s\n",
      "[CV 3/3] END C=0.3593813663804626, penalty=l2, solver=liblinear;, score=0.852 total time=  16.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.3593813663804626, penalty=l2, solver=lbfgs;, score=0.839 total time=  19.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.3593813663804626, penalty=l2, solver=lbfgs;, score=0.839 total time=  21.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.3593813663804626, penalty=l2, solver=lbfgs;, score=0.838 total time=  20.1s\n",
      "[CV 1/3] END C=2.782559402207126, penalty=l2, solver=liblinear;, score=0.852 total time=  16.7s\n",
      "[CV 2/3] END C=2.782559402207126, penalty=l2, solver=liblinear;, score=0.852 total time=  15.9s\n",
      "[CV 3/3] END C=2.782559402207126, penalty=l2, solver=liblinear;, score=0.852 total time=  19.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=2.782559402207126, penalty=l2, solver=lbfgs;, score=0.838 total time=  19.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=2.782559402207126, penalty=l2, solver=lbfgs;, score=0.839 total time=  21.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=2.782559402207126, penalty=l2, solver=lbfgs;, score=0.838 total time=  19.9s\n",
      "[CV 1/3] END C=21.54434690031882, penalty=l2, solver=liblinear;, score=0.852 total time=  16.8s\n",
      "[CV 2/3] END C=21.54434690031882, penalty=l2, solver=liblinear;, score=0.852 total time=  16.0s\n",
      "[CV 3/3] END C=21.54434690031882, penalty=l2, solver=liblinear;, score=0.852 total time=  16.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=21.54434690031882, penalty=l2, solver=lbfgs;, score=0.839 total time=  19.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=21.54434690031882, penalty=l2, solver=lbfgs;, score=0.839 total time=  21.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=21.54434690031882, penalty=l2, solver=lbfgs;, score=0.838 total time=  20.0s\n",
      "[CV 1/3] END C=166.81005372000556, penalty=l2, solver=liblinear;, score=0.852 total time=  16.6s\n",
      "[CV 2/3] END C=166.81005372000556, penalty=l2, solver=liblinear;, score=0.852 total time=  15.8s\n",
      "[CV 3/3] END C=166.81005372000556, penalty=l2, solver=liblinear;, score=0.852 total time=  16.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=166.81005372000556, penalty=l2, solver=lbfgs;, score=0.839 total time=  19.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=166.81005372000556, penalty=l2, solver=lbfgs;, score=0.839 total time=  20.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=166.81005372000556, penalty=l2, solver=lbfgs;, score=0.838 total time=  20.4s\n",
      "[CV 1/3] END C=1291.5496650148827, penalty=l2, solver=liblinear;, score=0.852 total time=  16.6s\n",
      "[CV 2/3] END C=1291.5496650148827, penalty=l2, solver=liblinear;, score=0.852 total time=  16.0s\n",
      "[CV 3/3] END C=1291.5496650148827, penalty=l2, solver=liblinear;, score=0.852 total time=  16.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1291.5496650148827, penalty=l2, solver=lbfgs;, score=0.839 total time=  19.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1291.5496650148827, penalty=l2, solver=lbfgs;, score=0.839 total time=  21.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1291.5496650148827, penalty=l2, solver=lbfgs;, score=0.838 total time=  20.5s\n",
      "[CV 1/3] END C=10000.0, penalty=l2, solver=liblinear;, score=0.852 total time=  17.0s\n",
      "[CV 2/3] END C=10000.0, penalty=l2, solver=liblinear;, score=0.852 total time=  16.1s\n",
      "[CV 3/3] END C=10000.0, penalty=l2, solver=liblinear;, score=0.852 total time=  16.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=10000.0, penalty=l2, solver=lbfgs;, score=0.840 total time=  21.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=10000.0, penalty=l2, solver=lbfgs;, score=0.839 total time=  22.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=10000.0, penalty=l2, solver=lbfgs;, score=0.838 total time=  21.6s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "selected_data = eastmoney[columns]\n",
    "selected_data.columns = selected_data.columns.str.strip()\n",
    "\n",
    "# 对 dominant_topic 进行独热编码\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "dominant_topic_encoded = encoder.fit_transform(selected_data[['dominant_topic']])\n",
    "encoded_df = pd.DataFrame(dominant_topic_encoded, columns=[f\"topic_{i}\" for i in range(dominant_topic_encoded.shape[1])])\n",
    "selected_data = pd.concat([selected_data.drop('dominant_topic', axis=1), encoded_df], axis=1)\n",
    "\n",
    "X2 = selected_data\n",
    "y2 = eastmoney['viral']\n",
    "\n",
    "# 标准化\n",
    "scaler = StandardScaler()\n",
    "sentiment_scores = X2['sentiment_score'].values.reshape(-1, 1)\n",
    "X2['sentiment_score'] = scaler.fit_transform(sentiment_scores)\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.3, random_state=42)\n",
    "\n",
    "# 计算类权重\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y2_train), y=y2_train)\n",
    "weights = {i : class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "# 将类权重添加到逻辑回归模型\n",
    "logistic_model = LogisticRegression(class_weight=weights)\n",
    "\n",
    "# 可能选择更多特征\n",
    "selector = RFE(logistic_model, n_features_to_select=5, step=1)\n",
    "selector.fit(X2_train, y2_train)\n",
    "\n",
    "\n",
    "# 定义要搜索的参数网格\n",
    "param_grid = {\n",
    "    'C': np.logspace(-4, 4, 10),\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['liblinear', 'lbfgs']\n",
    "}\n",
    "\n",
    "# 设置GridSearchCV\n",
    "grid_search = GridSearchCV(logistic_model, param_grid, cv=3, scoring='accuracy', verbose=3)\n",
    "grid_search.fit(X2_train, y2_train)\n",
    "\n",
    "# 使用最佳参数的模型\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 预测\n",
    "y2_pred = best_model.predict(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xJ9QalCnwDKu",
    "outputId": "f770840c-21ff-4796-d289-9227cb5f68cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.85      0.92   1886055\n",
      "         1.0       0.23      0.91      0.37     95054\n",
      "\n",
      "    accuracy                           0.85   1981109\n",
      "   macro avg       0.61      0.88      0.64   1981109\n",
      "weighted avg       0.96      0.85      0.89   1981109\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1602520  283535]\n",
      " [   8921   86133]]\n"
     ]
    }
   ],
   "source": [
    "# 评估\n",
    "print(\"Classification Report:\\n\", classification_report(y2_test, y2_pred))\n",
    "conf_matrix = confusion_matrix(y2_test, y2_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RVm1BTeOWBQ"
   },
   "source": [
    "Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bk2QBlcWKO9M",
    "outputId": "468d7b8f-9282-4a16-9392-be8ad2babfa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n",
      " [('eastmoney_robo_journalism', 1), ('SMA_robo_journalism', 1), ('colon_mark', 1), ('topic_0', 1), ('topic_4', 1), ('topic_3', 2), ('media_robo_journalism', 3), ('topic_2', 4), ('exclamation_mark', 5), ('question_mark', 6), ('topic_1', 7), ('month', 8), ('sentiment_score', 9), ('article_source_cate', 10), ('article_author', 11)]\n"
     ]
    }
   ],
   "source": [
    "feature_importance = list(zip(X2_train.columns, selector.ranking_))\n",
    "feature_importance.sort(key=lambda x: x[1])\n",
    "print(\"Feature importances:\\n\", feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j52MAhdb7YSV"
   },
   "source": [
    "Without class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y_LFBgK57XvH",
    "outputId": "ed3d901e-4c88-4400-8a1d-29b5428e300e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV 1/3] END C=9.999999999999999e-05, penalty=l2, solver=liblinear;, score=0.952 total time=  17.6s\n",
      "[CV 2/3] END C=9.999999999999999e-05, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
      "[CV 3/3] END C=9.999999999999999e-05, penalty=l2, solver=liblinear;, score=0.952 total time=  17.4s\n",
      "[CV 1/3] END C=9.999999999999999e-05, penalty=l2, solver=lbfgs;, score=0.952 total time=  30.7s\n",
      "[CV 2/3] END C=9.999999999999999e-05, penalty=l2, solver=lbfgs;, score=0.952 total time=  51.9s\n",
      "[CV 3/3] END C=9.999999999999999e-05, penalty=l2, solver=lbfgs;, score=0.952 total time= 1.0min\n",
      "[CV 1/3] END C=0.000774263682681127, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
      "[CV 2/3] END C=0.000774263682681127, penalty=l2, solver=liblinear;, score=0.952 total time=  18.6s\n",
      "[CV 3/3] END C=0.000774263682681127, penalty=l2, solver=liblinear;, score=0.952 total time=  18.6s\n",
      "[CV 1/3] END C=0.000774263682681127, penalty=l2, solver=lbfgs;, score=0.952 total time=  56.4s\n",
      "[CV 2/3] END C=0.000774263682681127, penalty=l2, solver=lbfgs;, score=0.952 total time=  29.1s\n",
      "[CV 3/3] END C=0.000774263682681127, penalty=l2, solver=lbfgs;, score=0.952 total time=  47.5s\n",
      "[CV 1/3] END C=0.005994842503189409, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
      "[CV 2/3] END C=0.005994842503189409, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
      "[CV 3/3] END C=0.005994842503189409, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
      "[CV 1/3] END C=0.005994842503189409, penalty=l2, solver=lbfgs;, score=0.953 total time=  55.6s\n",
      "[CV 2/3] END C=0.005994842503189409, penalty=l2, solver=lbfgs;, score=0.953 total time=  52.2s\n",
      "[CV 3/3] END C=0.005994842503189409, penalty=l2, solver=lbfgs;, score=0.952 total time=  27.1s\n",
      "[CV 1/3] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
      "[CV 2/3] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
      "[CV 3/3] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
      "[CV 1/3] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=0.953 total time= 1.6min\n",
      "[CV 2/3] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=0.953 total time=  50.4s\n",
      "[CV 3/3] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=0.952 total time=  43.2s\n",
      "[CV 1/3] END C=0.3593813663804626, penalty=l2, solver=liblinear;, score=0.952 total time=  18.6s\n",
      "[CV 2/3] END C=0.3593813663804626, penalty=l2, solver=liblinear;, score=0.952 total time=  18.6s\n",
      "[CV 3/3] END C=0.3593813663804626, penalty=l2, solver=liblinear;, score=0.952 total time=  18.4s\n",
      "[CV 1/3] END C=0.3593813663804626, penalty=l2, solver=lbfgs;, score=0.952 total time=  37.6s\n",
      "[CV 2/3] END C=0.3593813663804626, penalty=l2, solver=lbfgs;, score=0.952 total time=  25.6s\n",
      "[CV 3/3] END C=0.3593813663804626, penalty=l2, solver=lbfgs;, score=0.952 total time=  28.6s\n",
      "[CV 1/3] END C=2.782559402207126, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
      "[CV 2/3] END C=2.782559402207126, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
      "[CV 3/3] END C=2.782559402207126, penalty=l2, solver=liblinear;, score=0.952 total time=  18.3s\n",
      "[CV 1/3] END C=2.782559402207126, penalty=l2, solver=lbfgs;, score=0.953 total time=  54.8s\n",
      "[CV 2/3] END C=2.782559402207126, penalty=l2, solver=lbfgs;, score=0.953 total time= 1.1min\n",
      "[CV 3/3] END C=2.782559402207126, penalty=l2, solver=lbfgs;, score=0.952 total time=  37.0s\n",
      "[CV 1/3] END C=21.54434690031882, penalty=l2, solver=liblinear;, score=0.952 total time=  18.6s\n",
      "[CV 2/3] END C=21.54434690031882, penalty=l2, solver=liblinear;, score=0.952 total time=  18.6s\n",
      "[CV 3/3] END C=21.54434690031882, penalty=l2, solver=liblinear;, score=0.952 total time=  18.6s\n",
      "[CV 1/3] END C=21.54434690031882, penalty=l2, solver=lbfgs;, score=0.952 total time= 1.5min\n",
      "[CV 2/3] END C=21.54434690031882, penalty=l2, solver=lbfgs;, score=0.953 total time=  38.5s\n",
      "[CV 3/3] END C=21.54434690031882, penalty=l2, solver=lbfgs;, score=0.953 total time=  55.5s\n",
      "[CV 1/3] END C=166.81005372000556, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
      "[CV 2/3] END C=166.81005372000556, penalty=l2, solver=liblinear;, score=0.952 total time=  18.3s\n",
      "[CV 3/3] END C=166.81005372000556, penalty=l2, solver=liblinear;, score=0.952 total time=  18.4s\n",
      "[CV 1/3] END C=166.81005372000556, penalty=l2, solver=lbfgs;, score=0.952 total time=  20.9s\n",
      "[CV 2/3] END C=166.81005372000556, penalty=l2, solver=lbfgs;, score=0.952 total time=  32.8s\n",
      "[CV 3/3] END C=166.81005372000556, penalty=l2, solver=lbfgs;, score=0.953 total time= 1.2min\n",
      "[CV 1/3] END C=1291.5496650148827, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
      "[CV 2/3] END C=1291.5496650148827, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
      "[CV 3/3] END C=1291.5496650148827, penalty=l2, solver=liblinear;, score=0.952 total time=  18.6s\n",
      "[CV 1/3] END C=1291.5496650148827, penalty=l2, solver=lbfgs;, score=0.953 total time=  45.2s\n",
      "[CV 2/3] END C=1291.5496650148827, penalty=l2, solver=lbfgs;, score=0.953 total time=  48.1s\n",
      "[CV 3/3] END C=1291.5496650148827, penalty=l2, solver=lbfgs;, score=0.952 total time= 2.3min\n",
      "[CV 1/3] END C=10000.0, penalty=l2, solver=liblinear;, score=0.952 total time=  18.2s\n",
      "[CV 2/3] END C=10000.0, penalty=l2, solver=liblinear;, score=0.952 total time=  18.3s\n",
      "[CV 3/3] END C=10000.0, penalty=l2, solver=liblinear;, score=0.952 total time=  18.4s\n",
      "[CV 1/3] END C=10000.0, penalty=l2, solver=lbfgs;, score=0.952 total time=  22.6s\n",
      "[CV 2/3] END C=10000.0, penalty=l2, solver=lbfgs;, score=0.953 total time= 1.1min\n",
      "[CV 3/3] END C=10000.0, penalty=l2, solver=lbfgs;, score=0.952 total time=  19.8s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "selected_data = eastmoney[columns]\n",
    "selected_data.columns = selected_data.columns.str.strip()\n",
    "\n",
    "# 对 dominant_topic 进行独热编码\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "dominant_topic_encoded = encoder.fit_transform(selected_data[['dominant_topic']])\n",
    "encoded_df = pd.DataFrame(dominant_topic_encoded, columns=[f\"topic_{i}\" for i in range(dominant_topic_encoded.shape[1])])\n",
    "selected_data = pd.concat([selected_data.drop('dominant_topic', axis=1), encoded_df], axis=1)\n",
    "\n",
    "X2 = selected_data\n",
    "y2 = eastmoney['viral']\n",
    "\n",
    "# 使用标准化\n",
    "scaler = StandardScaler()\n",
    "sentiment_scores = X2['sentiment_score'].values.reshape(-1, 1)\n",
    "X2['sentiment_score'] = scaler.fit_transform(sentiment_scores)\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.3, random_state=42)\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# 可能选择更多特征\n",
    "selector = RFE(logistic_model, n_features_to_select=5, step=1)\n",
    "selector.fit(X2_train, y2_train)\n",
    "\n",
    "\n",
    "# 定义要搜索的参数网格\n",
    "param_grid = {\n",
    "    'C': np.logspace(-4, 4, 10),\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['liblinear', 'lbfgs']\n",
    "}\n",
    "\n",
    "# 设置GridSearchCV\n",
    "grid_search = GridSearchCV(logistic_model, param_grid, cv=3, scoring='accuracy', verbose=3)\n",
    "grid_search.fit(X2_train, y2_train)\n",
    "\n",
    "# 使用最佳参数的模型\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 预测\n",
    "y2_pred = best_model.predict(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JaKLpSD17XrT",
    "outputId": "bb38aaf5-a66c-4d44-ed6c-e0d3ca2b74d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.98   1886055\n",
      "         1.0       0.55      0.04      0.07     95054\n",
      "\n",
      "    accuracy                           0.95   1981109\n",
      "   macro avg       0.75      0.52      0.52   1981109\n",
      "weighted avg       0.93      0.95      0.93   1981109\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1883050    3005]\n",
      " [  91393    3661]]\n"
     ]
    }
   ],
   "source": [
    "# 评估\n",
    "print(\"Classification Report:\\n\", classification_report(y2_test, y2_pred))\n",
    "conf_matrix = confusion_matrix(y2_test, y2_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2YrxF0-9OgSq"
   },
   "source": [
    "Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dLegJxIh8HKd",
    "outputId": "0d91df3b-f329-4bc9-ebab-8df7044ee8ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n",
      " [('eastmoney_robo_journalism', 1), ('SMA_robo_journalism', 1), ('colon_mark', 1), ('topic_3', 1), ('topic_4', 1), ('topic_0', 2), ('media_robo_journalism', 3), ('topic_1', 4), ('question_mark', 5), ('topic_2', 6), ('exclamation_mark', 7), ('sentiment_score', 8), ('month', 9), ('article_source_cate', 10), ('article_author', 11)]\n"
     ]
    }
   ],
   "source": [
    "feature_importance = list(zip(X2_train.columns, selector.ranking_))\n",
    "feature_importance.sort(key=lambda x: x[1])\n",
    "print(\"Feature importances:\\n\", feature_importance)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "haMqQXwegh7q",
    "toZxlWepyRVA",
    "xxQblqMLVcsU",
    "iPW1-BTAuf_B"
   ],
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "MTL_project-BiIXOKA8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
